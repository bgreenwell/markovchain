\documentclass[
  nojss]{jss}

\usepackage[utf8]{inputenc}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\author{
Giorgio Alfredo Spedicato\\Ph.D C.Stat FCAS, FSA, CSPA Unipol Group \And Tae Seung Kang\\Ph.D student, Computer \& Information Science \& Engineering \And Sai Bhargav Yalamanchi\\B-Tech student, Electrical Engineering \And Deepak Yadav\\B-Tech student, Computer Science and Engineering \And Ignacio Cordón\\Software Engineer at source\{d\}
}
\title{The \pkg{markovchain} Package: A Package for Easily Handling Discrete Markov Chains in \proglang{R}}

\Plainauthor{Giorgio Alfredo Spedicato, Tae Seung Kang, Sai Bhargav Yalamanchi, Deepak Yadav, Ignacio Cordón}
\Plaintitle{The markovchain Package: A Package for Easily Handling Discrete Markov Chains in R}
\Shorttitle{\pkg{markovchain} package: discrete Markov chains in \proglang{R}}

\Abstract{
The \pkg{markovchain} package aims to fill a gap within the \proglang{R} framework providing S4 classes and methods for easily handling discrete time Markov chains, homogeneous and simple inhomogeneous ones as well as continuous time Markov chains. The S4 classes for handling and analysing discrete and continuous time Markov chains are presented, as well as functions and method for performing probabilistic and statistical analysis. Finally, some examples in which the package's functions are applied to Economics, Finance and Natural Sciences topics are shown.
}

\Keywords{discrete time Markov chains, continuous time Markov chains, transition matrices, communicating classes, periodicity, first passage time, stationary distributions}
\Plainkeywords{discrete time Markov chains, continuous time Markov chains, transition matrices, communicating classes, periodicity, first passage time, stationary distributions}

%% publication information
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{}
%% \Acceptdate{2012-06-04}

\Address{
    Giorgio Alfredo Spedicato\\
  Ph.D C.Stat FCAS, FSA, CSPA Unipol Group\\
  Via Firenze 11 Paderno Dugnano 20037 Italy\\
  E-mail: \email{spedygiorgio@gmail.com}\\
  URL: www.statisticaladvisor.com\\~\\
      Tae Seung Kang\\
  Ph.D student, Computer \& Information Science \& Engineering\\
  University of Florida Gainesville, FL, USA\\
  E-mail: \email{tskang3@gmail.com}\\
  
      Sai Bhargav Yalamanchi\\
  B-Tech student, Electrical Engineering\\
  Indian Institute of Technology, Bombay Mumbai - 400 076, India\\
  E-mail: \email{bhargavcoolboy@gmail.com}\\
  
      Deepak Yadav\\
  B-Tech student, Computer Science and Engineering\\
  Indian Institute of Technology, Varanasi Uttar Pradesh - 221 005, India\\
  E-mail: \email{deepakyadav.iitbhu@gmail.com}\\
  
      Ignacio Cordón\\
  Software Engineer at source\{d\}\\
  Madrid (Madrid), Spain\\
  E-mail: \email{nacho.cordon.castillo@gmail.com}\\
  
  }

% Pandoc header

\author{\small{Giorgio Alfredo Spedicato, Tae Seung Kang, Sai Bhargav Yalamanchi, Deepak Yadav, Ignacio Cordón}}

\Plainauthor{G.A. Spedicato, T.S. Kang, S.B. Yalamanchi, D. Yadav, I. Cordón} \usepackage{graphicx} \usepackage{amsmath} \usepackage{longtable} \usepackage{booktabs} \setkeys{Gin}{width=0.8\textwidth} \usepackage{amsfonts}

\begin{document}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Markov chains represent a class of stochastic processes of great interest for the wide spectrum of practical applications. In particular, discrete time Markov chains (DTMC) permit to model the transition probabilities between discrete states by the aid of matrices.Various \proglang{R} packages deal with models that are based on Markov chains:

\begin{itemize}
\tightlist
\item
  \pkg{msm} \citep{msmR} handles Multi-State Models for panel data.
\item
  \pkg{mcmcR} \citep{mcmcR} implements Monte Carlo Markov Chain approach.
\item
  \pkg{hmm} \citep{hmmR} fits hidden Markov models with covariates.
\item
  \pkg{mstate} fits `Multi-State Models based on Markov chains for survival analysis \citep{mstateR}.
\end{itemize}

Nevertheless, the \proglang{R} statistical environment \citep{rSoftware} seems to lack a simple package that coherently defines S4 classes for discrete Markov chains and allows to perform probabilistic analysis, statistical inference and applications. For the sake of completeness, \pkg{markovchain} is the second package specifically dedicated to DTMC analysis, being \pkg{DTMCPack} \citep{DTMCPackR} the first one. Notwithstanding, \pkg{markovchain} package \citep{pkg:markovchain} aims to offer more flexibility in handling DTMC than other existing solutions, providing S4 classes for both homogeneous and non-homogeneous Markov chains as well as methods suited to perform statistical and probabilistic analysis.

The \pkg{markovchain} package depends on the following \proglang{R} packages: \pkg{expm} \citep{expmR} to perform efficient matrices powers; \pkg{igraph} \citep{pkg:igraph} to perform pretty plotting of \texttt{markovchain} objects and \pkg{matlab} \citep{pkg:matlab}, that contains functions for matrix management and calculations that emulate those within \proglang{MATLAB} environment. Moreover, other scientific softwares provide functions specifically designed to analyze DTMC, as \proglang{Mathematica} 9 \citep{mathematica9}.

The paper is structured as follows: Section \ref{sec:mathematics} briefly reviews mathematics and definitions regarding DTMC, Section \ref{sec:structure} discusses how to handle and manage Markov chain objects within the package, Section \ref{sec:probability} and Section \ref{sec:statistics} show how to perform probabilistic and statistical modelling, while Section \ref{sec:applications} presents some applied examples from various fields analyzed by means of the \pkg{markovchain} package.

\hypertarget{sec:mathematics}{%
\section{Review of core mathematical concepts}\label{sec:mathematics}}

\hypertarget{general-definitions}{%
\subsection{General Definitions}\label{general-definitions}}

A DTMC is a sequence of random variables \(X_{1},\: X_{2}\: ,\ldots,\:X_{n},\ldots\) characterized by the Markov property (also known as memoryless property, see Equation \ref{eq:markovProp}). The Markov property states that the distribution of the forthcoming state \(X_{n+1}\) depends only on the current state \(X_{n}\) and doesn't depend on the previous ones \(X_{n-1},\: X_{n-2},\ldots,\: X_{1}\).

\begin{equation}
Pr\left(X_{n+1}=x_{n+1}\left|X_{1}=x_{1},X_{2}=x_{2,}...,X_{n}=x_{n}\right.\right)=Pr\left(X_{n+1}=x_{n+1}\left|X_{n}=x_{n}\right.\right).
\label{eq:markovProp}
\end{equation}

The set of possible states \(S=\left\{ s_{1},s_{2},...,s_{r}\right\}\) of \(X_{n}\) can be finite or countable and it is named the state space of the chain.

The chain moves from one state to another (this change is named either `transition' or `step') and the probability \(p_{ij}\) to move from state \(s_{i}\) to state \(s_{j}\) in one step is named transition probability:

\begin{equation}
p_{ij}=Pr\left(X_{1}=s_{j}\left|X_{0}=s_{i}\right.\right).
\label{eq:trProp}
\end{equation}

The probability of moving from state \(i\) to \(j\) in \(n\) steps is denoted by \(p_{ij}^{(n)}=Pr\left(X_{n}=s_{j}\left|X_{0}=s_{i}\right.\right)\).

A DTMC is called time-homogeneous if the property shown in Equation \ref{eq:mcHom} holds. Time homogeneity implies no change in the underlying transition probabilities as time goes on.
\begin{equation}
Pr\left(X_{n+1}=s_{j}\left|X_{n}=s_{i}\right.\right)=Pr\left(X_{n}=s_{j}\left|X_{n-1}=s_{i}\right.\right).
\label{eq:mcHom}
\end{equation}

If the Markov chain is time-homogeneous, then \(p_{ij}=Pr\left(X_{k+1}=s_{j}\left|X_{k}=s_{i}\right.\right)\) and \newline \(p_{ij}^{(n)}=Pr\left(X_{n+k}=s_{j}\left|X_{k}=s_{i}\right.\right)\), where \(k>0\).

The probability distribution of transitions from one state to another can be represented into a transition matrix \(P=(p_{ij})_{i,j}\), where each element of position \((i,j)\) represents the transition probability \(p_{ij}\). E.g., if \(r=3\) the transition matrix \(P\) is shown in Equation \ref{eq:trPropEx}

\begin{equation}
P=\left[\begin{array}{ccc}
p_{11} & p_{12} & p_{13}\\
p_{21} & p_{22} & p_{23}\\
p_{31} & p_{32} & p_{33}
\end{array}\right].
\label{eq:trPropEx}
\end{equation}

The distribution over the states can be written in the form of a stochastic row vector \(x\) (the term stochastic means that \(\sum_{i}x_{i}=1, x_{i} \geq 0\)): e.g., if the current state of \(x\) is \(s_{2}\), \(x=\left(0\:1\:0\right)\). As a consequence, the relation between \(x^{(1)}\) and \(x^{(0)}\) is \(x^{(1)}=x^{(0)}P\) and, recursively, we get \(x^{(2)}=x^{(0)}P^{2}\) and \(x^{(n)}=x^{(0)}P^{n},\, n>0\).

DTMC are explained in most theory books on stochastic processes, see \cite{bremaud1999discrete} and \cite{dobrow2016introduction} for example. Valuable references online available are: \cite{konstantopoulos2009markov}, \cite{probBook} and \cite{bardPpt}.

\hypertarget{sec:properties}{%
\subsection{Properties and classification of states}\label{sec:properties}}

A state \(s_{j}\) is said accessible from state \(s_{i}\) (written \(s_{i}\rightarrow s_{j}\)) if a system starting in state \(s_{i}\) has a positive probability to reach the state \(s_{j}\) at a certain point, i.e., \(\exists n>0:\: p_{ij}^{n}>0\). If both \(s_{i}\rightarrow s_{j}\) and \(s_{j}\rightarrow s_{i}\), then
\(s_{i}\) and \(s_{j}\) are said to communicate.

A communicating class is defined to be a set of states that communicate. A DTMC can be composed by one or more communicating classes. If the DTMC is composed by only one communicating class (i.e., if all states in the chain communicate), then it is said irreducible. A communicating class is said to be closed if no states outside of the class can be reached from any state inside it.

If \(p_{ii}=1\), \(s_{i}\) is defined as absorbing state: an absorbing state corresponds to a closed communicating class composed by one state only.

The canonic form of a DTMC transition matrix is a matrix having a block form, where the closed communicating classes are shown at the beginning of the diagonal matrix.

A state \(s_{i}\) has period \(k_{i}\) if any return to state \(s_{i}\) must occur in multiplies of \(k_{i}\) steps, that is \(k_{i}=gcd\left\{ n:Pr\left(X_{n}=s_{i}\left|X_{0}=s_{i}\right.\right)>0\right\}\), where \(gcd\) is the greatest common divisor. If \(k_{i}=1\) the state \(s_{i}\) is said to be aperiodic, else if \(k_{i}>1\) the state \(s_{i}\) is periodic with period \(k_{i}\). Loosely speaking, \(s_{i}\) is periodic if it can only return to itself after a fixed number of transitions \(k_{i}>1\) (or multiple of \(k_{i}\)), else it is aperiodic.

If states \(s_{i}\) and \(s_{j}\) belong to the same communicating class, then they have the same period \(k_{i}\). As a consequence, each of the states of an irreducible DTMC share the same periodicity. This periodicity is also considered the DTMC periodicity. It is possible to classify states according to their periodicity. Let \(T^{x\rightarrow x}\) is the number of periods to go back to state \(x\) knowing that the chain starts in \(x\).

\begin{itemize}
\tightlist
\item
  A state \(x\) is recurrent if \(P(T^{x\rightarrow x}<+\infty)=1\) (equivalently \(P(T^{x\rightarrow x}=+\infty)=0\)). In addition:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    A state \(x\) is null recurrent if in addition \(E(T^{x\rightarrow x})=+\infty\).
  \item
    A state \(x\) is positive recurrent if in addition \(E(T^{x\rightarrow x})<+\infty\).
  \item
    A state \(x\) is absorbing if in addition \(P(T^{x\rightarrow x}=1)=1\).
  \end{enumerate}
\item
  A state \(x\) is transient if \(P(T^{x\rightarrow x}<+\infty)<1\) (equivalently \(P(T^{x\rightarrow x}=+\infty)>0\)).
\end{itemize}

It is possible to analyze the timing to reach a certain state. The first passage time (or hitting time) from state \(s_{i}\) to state \(s_{j}\) is the number \(T_{ij}\) of steps taken by the chain until it arrives for the first time to state \(s_{j}\), given that \(X_{0} = s_{i}\). The probability distribution of \(T_{ij}\) is defined by Equation \ref{eq:fpt1}

\begin{equation}
{h_{ij}}^{\left( n \right)} = Pr\left( {T_{ij} = n} \right) = Pr\left( X_n = s_j,X_{n - 1} \ne s_{j}, \ldots ,X_1 \ne s_j |X_0 = s_i \right)
\label{eq:fpt1}
\end{equation}

and can be found recursively using Equation \ref{eq:ftp2}, given that \({h_{ij}}^{\left( n \right)} = p_{ij}\).

\begin{equation}
{h_{ij}}^{\left( n \right)} = \sum\limits_{k \in S - \left\{ s_{j} \right\}}^{} {{p_{ik}}{h_{kj}}^{\left( {n - 1} \right)}}.
\label{eq:ftp2}
\end{equation}

A commonly used quantity related to \(h\) is its average value, i.e.~the \emph{mean first passage time} (also expected hitting time), namely \(\bar h_{ij}= \sum_{n=1\dots\infty} n \,h_{ij}^{(n)}\).

If in the definition of the first passage time we let \(s_{i}=s_{j}\), we obtain the first recurrence time \(T_{i}=\inf \{ n\geq1:X_{n}=s_{i}|X_{0}=s_{i} \}\). We could also ask ourselves which is the \emph{mean recurrence time}, an average of the mean first recurrence times:

\[
 r_i = \sum_{k = 1}^{\infty} k \cdot P(T_i = k)
\]

Revisiting the definition of recurrence and transience: a state \(s_{i}\) is said to be recurrent if it is visited infinitely often, i.e., \(Pr(T_{i}<+\infty|X_{0}=s_{i})=1\). On the opposite, \(s_{i}\) is called transient if there is a positive probability that the chain will never return to \(s_{i}\), i.e., \(Pr(T_{i}=+\infty|X_{0}=s_{i})>0\).

Given a time homogeneous Markov chain with transition matrix \emph{P}, a stationary distribution \emph{z} is a stochastic row vector such that \(z=z\cdot P\), where \(0\leq z_{j}\leq 1 \: \forall j\) and \(\sum_{j}z_{j}=1\).

If a DTMC \(\{X_{n}\}\) is irreducible and aperiodic, then it has a limit distribution and this distribution is stationary. As a consequence, if \(P\) is the \(k\times k\) transition matrix of the chain and \(z=\left(z_{1},...,z_{k}\right)\) is the unique eigenvector of \(P\) such that \(\sum_{i=1}^{k}z_{i}=1\), then we get

\begin{equation}
  \underset{n\rightarrow\infty}{lim}P^{n}=Z,
  \label{eq:limMc}
\end{equation}

where \(Z\) is the matrix having all rows equal to \(z\). The stationary distribution of \(\{X_{n}\}\) is represented by \(z\).

A matrix \(A\) is called primitive if all of its entries are strictly positive, and we write it \(A > 0\). If the transition matrix \(P\) for a DTMC has some primitive power, i.e.~it exists \(m > 0: P^m > 0\), then the DTMC is said to be regular. In fact being regular is equivalent to being irreducible and aperiodic. All regular DTMCs are irreducible. The counterpart is not true.

Given two absorbing states \(s_A\) (source) and \(s_B\) (sink), the \emph{committor probability} \(q_j^{(AB)}\) is the probability that a process starting in state \(s_i\) is absorbed in state \(s_B\) (rather than \(s_A\)) \citep{noe_constructing_2009}. It can be computed via

\begin{equation}
 q_j^{(AB)} = \sum_{k \ni {A, B}} P_{jk}q_k^{(AB)} \quad \mbox{with} \quad
 q_A^{(AB)} = 0 \quad \mbox{and} \quad  q_B^{(AB)} = 1
\end{equation}

Note we can also define the hitting probability from \(i\) to \(j\) as the probability of ever reaching the state \(j\) if our initial state is \(i\):

\begin{equation}
h_{i,j} = Pr(T_{ij} < \infty) = \sum_{n = 0}^{\infty} h_{ij}^{(n)}
\label{eq:hitting-probs}
\end{equation}

In a DTMC with finite set of states, we know that a transient state communicates at least with one recurrent state. If the chain starts in a transient element, once it hits a recurrent state, it is going to be caught in its recurrent state, and we cannot expect it would go back to the initial state. Given a transient state \(i\) we can define the \emph{absorption probability} to the recurrent state \(j\) as the probability that the first recurrent state that the Markov chain visits (and therefore gets absorbed by its recurrent class) is \(j\), \(f^{*}_ij\). We can also define the \emph{mean absorption time} as the mean number of steps the transient state \(i\) would take until it hits any recurrent state, \(b_i\).

\hypertarget{a-short-example}{%
\subsection{A short example}\label{a-short-example}}

Consider the following numerical example. Suppose we have a DTMC with a set of 3 possible states \(S=\{s_{1}, s_{2}, s_{3}\}\). Let the transition matrix be:
\begin{equation}
P=\left[\begin{array}{ccc}
0.5 & 0.2 & 0.3\\
0.15 & 0.45 & 0.4\\
0.25 & 0.35 & 0.4
\end{array}\right].
\label{eq:trPropExEx1}
\end{equation}

In \(P\), \(p_{11}=0.5\) is the probability that \(X_{1}=s_{1}\) given that we observed \(X_{0}=s_{1}\) is 0.5, and so on.It is easy to see that the chain is irreducible since all the states communicate (it is made by one communicating class only).

Suppose that the current state of the chain is \(X_{0}=s_{2}\), i.e., \(x^{(0)}=(0\:1\:0)\), then the probability distribution of states after 1 and 2 steps can be computed as shown in Equations \eqref{eq:trPropExEx2} and \eqref{eq:trPropExEx3}.

\begin{equation}
x^{(1)}=\left(0\:1\:0\right)\left[\begin{array}{ccc}
0.5 & 0.2 & 0.3\\
0.15 & 0.45 & 0.4\\
0.25 & 0.35 & 0.4
\end{array}\right]=\left(0.15\:0.45\:0.4\right).
\label{eq:trPropExEx2}
\end{equation}

\begin{equation}
x^{(n)}=x^{(n-1)}P \to \left(0.15\:0.45\:0.4\right)\left[\begin{array}{ccc}
0.5 & 0.2 & 0.3\\
0.15 & 0.45 & 0.4\\
0.25 & 0.35 & 0.4
\end{array}\right]=\left(0.2425\:0.3725\:0.385\right).
\label{eq:trPropExEx3}
\end{equation}

If we were interested in the probability of being in the state \(s_{3}\) in the second step, then \(Pr\left(X_{2}=s_{3}\left|X_{0}=s_{2}\right.\right)=0.385\).

\newpage

\hypertarget{sec:structure}{%
\section{The structure of the package}\label{sec:structure}}

\hypertarget{creating-markovchain-objects}{%
\subsection{Creating markovchain objects}\label{creating-markovchain-objects}}

The package is loaded within the \proglang{R} command line as follows:

\begin{CodeChunk}

\begin{CodeInput}
R> library("markovchain")
\end{CodeInput}
\end{CodeChunk}

\begin{CodeChunk}

\begin{CodeOutput}

Attaching package: 'matlab'
\end{CodeOutput}

\begin{CodeOutput}
The following object is masked from 'package:stats':

    reshape
\end{CodeOutput}

\begin{CodeOutput}
The following objects are masked from 'package:utils':

    find, fix
\end{CodeOutput}

\begin{CodeOutput}
The following object is masked from 'package:base':

    sum
\end{CodeOutput}
\end{CodeChunk}

The \texttt{markovchain} and \texttt{markovchainList} S4 classes \citep{chambers} are defined within the \pkg{markovchain} package as displayed:

\begin{CodeChunk}

\begin{CodeOutput}
Class "markovchain" [package "markovchain"]

Slots:
                                                                          
Name:            states            byrow transitionMatrix             name
Class:        character          logical           matrix        character
\end{CodeOutput}

\begin{CodeOutput}
Class "markovchainList" [package "markovchain"]

Slots:
                                
Name:  markovchains         name
Class:         list    character
\end{CodeOutput}
\end{CodeChunk}

The first class has been designed to handle homogeneous Markov chain processes, while the latter (which is itself a list of \texttt{markovchain} objects) has been designed to handle non-homogeneous Markov chains processes.

Any element of \texttt{markovchain} class is comprised by following slots:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{states}: a character vector, listing the states for which transition probabilities are defined.
\item
  \texttt{byrow}: a logical element, indicating whether transition probabilities are shown by row or by column.
\item
  \texttt{transitionMatrix}: the probabilities of the transition matrix.
\item
  \texttt{name}: optional character element to name the DTMC.
\end{enumerate}

The \texttt{markovchainList} objects are defined by following slots:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{markovchains}: a list of \texttt{markovchain} objects.
\item
  \texttt{name}: optional character element to name the DTMC.
\end{enumerate}

The \texttt{markovchain} objects can be created either in a long way, as the following code shows

\begin{CodeChunk}

\begin{CodeInput}
R> weatherStates <- c("sunny", "cloudy", "rain")
R> byRow <- TRUE
R> weatherMatrix <- matrix(data = c(0.70, 0.2, 0.1,
R+                        0.3, 0.4, 0.3,
R+                        0.2, 0.45, 0.35), byrow = byRow, nrow = 3,
R+                      dimnames = list(weatherStates, weatherStates))
R> mcWeather <- new("markovchain", states = weatherStates, byrow = byRow, 
R+                transitionMatrix = weatherMatrix, name = "Weather")
\end{CodeInput}
\end{CodeChunk}

or in a shorter way, displayed below

\begin{CodeChunk}

\begin{CodeInput}
R> mcWeather <- new("markovchain", states = c("sunny", "cloudy", "rain"),
R+                  transitionMatrix = matrix(data = c(0.70, 0.2, 0.1,
R+                        0.3, 0.4, 0.3,
R+                        0.2, 0.45, 0.35), byrow = byRow, nrow = 3), 
R+                  name = "Weather")
\end{CodeInput}
\end{CodeChunk}

When \texttt{new("markovchain")} is called alone, a default Markov chain is created.

\begin{CodeChunk}

\begin{CodeInput}
R> defaultMc <- new("markovchain")
\end{CodeInput}
\end{CodeChunk}

The quicker way to create \texttt{markovchain} objects is made possible thanks to the implemented \texttt{initialize} S4 method that checks that:

\begin{itemize}
\tightlist
\item
  the \texttt{transitionMatrix} to be a transition matrix, i.e., all entries to be probabilities and either all rows or all columns to sum up to one.
\item
  the columns and rows names of \texttt{transitionMatrix} to be defined and to coincide with \texttt{states} vector slot.
\end{itemize}

The \texttt{markovchain} objects can be collected in a list within \texttt{markovchainList} S4 objects as following example shows.

\begin{CodeChunk}

\begin{CodeInput}
R> mcList <- new("markovchainList", markovchains = list(mcWeather, defaultMc), 
R+                name = "A list of Markov chains")
\end{CodeInput}
\end{CodeChunk}

\hypertarget{handling-markovchain-objects}{%
\subsection{Handling markovchain objects}\label{handling-markovchain-objects}}

Table \ref{tab:methodsToHandleMc} lists which methods handle and manipulate \texttt{markovchain} objects.

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \hline
  Method & Purpose \\
    \hline  \hline
  \code{*} & Direct multiplication for transition matrices.\\
  \code{\textasciicircum{}} & Compute the power \code{markovchain} of a given one.\\
  \code{[} & Direct access to the elements of the transition matrix.\\
  \code{==} & Equality operator between two transition matrices.\\
  \code{!=} & Inequality operator between two transition matrices.\\
  \code{as} & Operator to convert \code{markovchain} objects into \code{data.frame} and\\
  & \code{table} object.\\
  \code{dim} & Dimension of the transition matrix.\\
  \code{names} & Equal to \code{states}.\\
  \code{names<-} & Change the \code{states} name.\\
  \code{name} & Get the name of \code{markovchain object}.\\
  \code{name<-} & Change the name of \code{markovchain object}.\\
  \code{plot} & \code{plot} method for \code{markovchain} objects.\\
  \code{print} & \code{print} method for \code{markovchain} objects.\\
  \code{show} & \code{show} method for \code{markovchain} objects.\\
  \code{sort} & \code{sort} method for \code{markovchain} objects, in terms of their states.\\
  \code{states} & Name of the transition states.\\
  \code{t} & Transposition operator (which switches \code{byrow} `slot value and modifies \\
  &  the transition matrix coherently).\\
  \hline
\end{tabular}
\caption{\pkg{markovchain} methods for handling \code{markovchain} objects.}
\label{tab:methodsToHandleMc}
\end{table}

The examples that follow shows how operations on \texttt{markovchain} objects can be easily performed. For example, using the previously defined matrix we can find what is the probability distribution of expected weather states in two and seven days, given the actual state to be cloudy.

\begin{CodeChunk}

\begin{CodeInput}
R> initialState <- c(0, 1, 0)
R> after2Days <- initialState * (mcWeather * mcWeather)
R> after7Days <- initialState * (mcWeather ^ 7)
R> after2Days
\end{CodeInput}

\begin{CodeOutput}
     sunny cloudy  rain
[1,]  0.39  0.355 0.255
\end{CodeOutput}

\begin{CodeInput}
R> round(after7Days, 3)
\end{CodeInput}

\begin{CodeOutput}
     sunny cloudy  rain
[1,] 0.462  0.319 0.219
\end{CodeOutput}
\end{CodeChunk}

A similar answer could have been obtained defining the vector of probabilities as a column vector. A column - defined probability matrix could be set up either creating a new matrix or transposing an existing \texttt{markovchain} object thanks to the \texttt{t} method.

\begin{CodeChunk}

\begin{CodeInput}
R> initialState <- c(0, 1, 0)
R> after2Days <- (t(mcWeather) * t(mcWeather)) * initialState
R> after7Days <- (t(mcWeather) ^ 7) * initialState
R> after2Days
\end{CodeInput}

\begin{CodeOutput}
        [,1]
sunny  0.390
cloudy 0.355
rain   0.255
\end{CodeOutput}

\begin{CodeInput}
R> round(after7Days, 3)
\end{CodeInput}

\begin{CodeOutput}
        [,1]
sunny  0.462
cloudy 0.319
rain   0.219
\end{CodeOutput}
\end{CodeChunk}

The initial state vector previously shown can not necessarily be a probability vector, as the code that follows shows:

\begin{CodeChunk}

\begin{CodeInput}
R> fvals<-function(mchain,initialstate,n) {
R+   out<-data.frame()
R+   names(initialstate)<-names(mchain)
R+   for (i in 0:n)
R+   {
R+     iteration<-initialstate*mchain^(i)
R+     out<-rbind(out,iteration)
R+   }
R+   out<-cbind(out, i=seq(0,n))
R+   out<-out[,c(4,1:3)]
R+   return(out)
R+ }
R> fvals(mchain=mcWeather,initialstate=c(90,5,5),n=4)
\end{CodeInput}

\begin{CodeOutput}
  i    sunny   cloudy     rain
1 0 90.00000  5.00000  5.00000
2 1 65.50000 22.25000 12.25000
3 2 54.97500 27.51250 17.51250
4 3 50.23875 29.88063 19.88062
5 4 48.10744 30.94628 20.94628
\end{CodeOutput}
\end{CodeChunk}

Basic methods have been defined for \texttt{markovchain} objects to quickly get states and transition matrix dimension.

\begin{CodeChunk}

\begin{CodeInput}
R> states(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
[1] "sunny"  "cloudy" "rain"  
\end{CodeOutput}

\begin{CodeInput}
R> names(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
[1] "sunny"  "cloudy" "rain"  
\end{CodeOutput}

\begin{CodeInput}
R> dim(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
[1] 3
\end{CodeOutput}
\end{CodeChunk}

Methods are available to set and get the name of \texttt{markovchain} object.

\begin{CodeChunk}

\begin{CodeInput}
R> name(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
[1] "Weather"
\end{CodeOutput}

\begin{CodeInput}
R> name(mcWeather) <- "New Name"
R> name(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
[1] "New Name"
\end{CodeOutput}
\end{CodeChunk}

Also it is possible to alphabetically sort the transition matrix:

\begin{CodeChunk}

\begin{CodeInput}
R> markovchain:::sort(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
New Name 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 cloudy, rain, sunny 
 The transition matrix  (by rows)  is defined as follows: 
       cloudy rain sunny
cloudy   0.40 0.30   0.3
rain     0.45 0.35   0.2
sunny    0.20 0.10   0.7
\end{CodeOutput}
\end{CodeChunk}

A direct access to transition probabilities is provided both by \texttt{transitionProbability} method and \texttt{"{[}"} method.

\begin{CodeChunk}

\begin{CodeInput}
R> transitionProbability(mcWeather, "cloudy", "rain")
\end{CodeInput}

\begin{CodeOutput}
[1] 0.3
\end{CodeOutput}

\begin{CodeInput}
R> mcWeather[2,3]
\end{CodeInput}

\begin{CodeOutput}
[1] 0.3
\end{CodeOutput}
\end{CodeChunk}

The transition matrix of a \texttt{markovchain} object can be displayed using \texttt{print} or \texttt{show} methods (the latter being less verbose). Similarly, the underlying transition probability diagram can be plotted by the use of \texttt{plot} method (as shown in Figure \ref{fig:mcPlot}) which is based on \pkg{igraph} package \citep{pkg:igraph}. \texttt{plot} method for \texttt{markovchain} objects is a wrapper of \texttt{plot.igraph} for \texttt{igraph} S4 objects defined within the \pkg{igraph} package. Additional parameters can be passed to \texttt{plot} function to control the network graph layout. There are also \pkg{diagram} and \pkg{DiagrammeR} ways available for plotting as shown in Figure \ref{fig:mcPlotdiagram}. The \texttt{plot} function also uses \texttt{communicatingClasses} function to separate out states of different communicating classes. All states that belong to one class have same colour.

\begin{CodeChunk}

\begin{CodeInput}
R> print(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
       sunny cloudy rain
sunny    0.7   0.20 0.10
cloudy   0.3   0.40 0.30
rain     0.2   0.45 0.35
\end{CodeOutput}

\begin{CodeInput}
R> show(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
New Name 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 sunny, cloudy, rain 
 The transition matrix  (by rows)  is defined as follows: 
       sunny cloudy rain
sunny    0.7   0.20 0.10
cloudy   0.3   0.40 0.30
rain     0.2   0.45 0.35
\end{CodeOutput}
\end{CodeChunk}

\begin{CodeChunk}

\begin{CodeOutput}

Attaching package: 'igraph'
\end{CodeOutput}

\begin{CodeOutput}
The following objects are masked from 'package:stats':

    decompose, spectrum
\end{CodeOutput}

\begin{CodeOutput}
The following object is masked from 'package:base':

    union
\end{CodeOutput}
\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{/tmp/RtmpghR4s0/file36246af82052/articles/an_introduction_to_markovchain_package_files/figure-latex/mcPlot-1} 

}

\caption[Weather example]{Weather example. Markov chain plot}\label{fig:mcPlot}
\end{figure}
\end{CodeChunk}

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{/tmp/RtmpghR4s0/file36246af82052/articles/an_introduction_to_markovchain_package_files/figure-latex/mcPlotdiagram-1} 

}

\caption[Weather example]{Weather example. Markov chain plot with diagram}\label{fig:mcPlotdiagram}
\end{figure}
\end{CodeChunk}

If one would like to use the \pkg{MmgraphR} package \citep{pkg:MmgraphR} to plot the transition matric, the following code shows how to do:

\begin{CodeChunk}

\begin{CodeInput}
R> suppressPackageStartupMessages(library("MmgraphR"))
R> stochastic_matrix_to_plot <- as(mcWeather, "matrix")
R> trmatplot(stochastic_matrix_to_plot, main = "Weather MC plot using MmgraphR", rowconstraint = FALSE)
\end{CodeInput}


\begin{center}\includegraphics[width=0.7\linewidth]{/tmp/RtmpghR4s0/file36246af82052/articles/an_introduction_to_markovchain_package_files/figure-latex/MmgraphR_plot-1} \end{center}

\end{CodeChunk}

Import and export from some specific classes is possible, as shown in Figure \ref{fig:fromAndTo} and in the following code.

\begin{CodeChunk}

\begin{CodeInput}
R> mcDf <- as(mcWeather, "data.frame")
R> mcNew <- as(mcDf, "markovchain")
R> mcDf
\end{CodeInput}

\begin{CodeOutput}
      t0     t1 prob
1  sunny  sunny 0.70
2  sunny cloudy 0.20
3  sunny   rain 0.10
4 cloudy  sunny 0.30
5 cloudy cloudy 0.40
6 cloudy   rain 0.30
7   rain  sunny 0.20
8   rain cloudy 0.45
9   rain   rain 0.35
\end{CodeOutput}

\begin{CodeInput}
R> mcIgraph <- as(mcWeather, "igraph")
\end{CodeInput}
\end{CodeChunk}

\begin{CodeChunk}

\begin{CodeInput}
R> require(msm)
\end{CodeInput}

\begin{CodeOutput}
Loading required package: msm
\end{CodeOutput}

\begin{CodeInput}
R> Q <- rbind ( c(0, 0.25, 0, 0.25),
R+              c(0.166, 0, 0.166, 0.166),
R+              c(0, 0.25, 0, 0.25),
R+              c(0, 0, 0, 0) )
R> cavmsm <- msm(state ~ years, subject = PTNUM, data = cav, qmatrix = Q, death = 4)
R> msmMc <- as(cavmsm, "markovchain")
R> msmMc
\end{CodeInput}

\begin{CodeOutput}
Unnamed Markov chain 
 A  4 - dimensional discrete Markov Chain defined by the following states: 
 State 1, State 2, State 3, State 4 
 The transition matrix  (by rows)  is defined as follows: 
            State 1    State 2    State 3    State 4
State 1 0.853958721 0.08836953 0.01475543 0.04291632
State 2 0.155576908 0.56663284 0.20599563 0.07179462
State 3 0.009903994 0.07853691 0.65965727 0.25190183
State 4 0.000000000 0.00000000 0.00000000 1.00000000
\end{CodeOutput}
\end{CodeChunk}

\begin{CodeChunk}

\begin{CodeInput}
R> library(etm)
R> data(sir.cont)
R> sir.cont <- sir.cont[order(sir.cont$id, sir.cont$time), ]
R> for (i in 2:nrow(sir.cont)) {
R+   if (sir.cont$id[i]==sir.cont$id[i-1]) {
R+     if (sir.cont$time[i]==sir.cont$time[i-1]) {
R+       sir.cont$time[i-1] <- sir.cont$time[i-1] - 0.5
R+     }
R+   }
R+ }
R> tra <- matrix(ncol=3,nrow=3,FALSE)
R> tra[1, 2:3] <- TRUE
R> tra[2, c(1, 3)] <- TRUE
R> tr.prob <- etm(sir.cont, c("0", "1", "2"), tra, "cens", 1)
R> tr.prob
\end{CodeInput}

\begin{CodeOutput}
Multistate model with 2 transient state(s)
 and 1 absorbing state(s)

Possible transitions:
 from to
    0  1
    0  2
    1  0
    1  2

Estimate of P(1, 183)
  0 1 2
0 0 0 1
1 0 0 1
2 0 0 1
\end{CodeOutput}

\begin{CodeInput}
R> etm2mc<-as(tr.prob, "markovchain")
R> etm2mc
\end{CodeInput}

\begin{CodeOutput}
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 0, 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          0         1         2
0 0.0000000 0.5000000 0.5000000
1 0.5000000 0.0000000 0.5000000
2 0.3333333 0.3333333 0.3333333
\end{CodeOutput}
\end{CodeChunk}

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{/tmp/RtmpghR4s0/file36246af82052/articles/an_introduction_to_markovchain_package_files/figure-latex/fromAndTo-1} 

}

\caption[The markovchain methods for import and export]{The markovchain methods for import and export}\label{fig:fromAndTo}
\end{figure}
\end{CodeChunk}

Coerce from \texttt{matrix} method, as the code below shows, represents another approach to create a \texttt{markovchain} method starting from a given squared probability matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> myMatr<-matrix(c(.1,.8,.1,.2,.6,.2,.3,.4,.3), byrow=TRUE, ncol=3)
R> myMc<-as(myMatr, "markovchain")
R> myMc
\end{CodeInput}

\begin{CodeOutput}
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 s1, s2, s3 
 The transition matrix  (by rows)  is defined as follows: 
    s1  s2  s3
s1 0.1 0.8 0.1
s2 0.2 0.6 0.2
s3 0.3 0.4 0.3
\end{CodeOutput}
\end{CodeChunk}

Non-homogeneous Markov chains can be created with the aid of \texttt{markovchainList} object. The example that follows arises from health insurance, where the costs associated to patients in a Continuous Care Health Community (CCHC) are modelled by a non-homogeneous Markov Chain, since the transition probabilities change by year. Methods explicitly written for \texttt{markovchainList} objects are: \texttt{print}, \texttt{show}, \texttt{dim} and \texttt{{[}}.

\begin{CodeChunk}

\begin{CodeInput}
R> stateNames = c("H", "I", "D")
R> Q0 <- new("markovchain", states = stateNames, 
R+         transitionMatrix =matrix(c(0.7, 0.2, 0.1,0.1, 0.6, 0.3,0, 0, 1), 
R+         byrow = TRUE, nrow = 3), name = "state t0")
R> Q1 <- new("markovchain", states = stateNames, 
R+         transitionMatrix = matrix(c(0.5, 0.3, 0.2,0, 0.4, 0.6,0, 0, 1), 
R+         byrow = TRUE, nrow = 3), name = "state t1")
R> Q2 <- new("markovchain", states = stateNames, 
R+         transitionMatrix = matrix(c(0.3, 0.2, 0.5,0, 0.2, 0.8,0, 0, 1), 
R+         byrow = TRUE,nrow = 3), name = "state t2")
R> Q3 <- new("markovchain", states = stateNames, 
R+           transitionMatrix = matrix(c(0, 0, 1, 0, 0, 1, 0, 0, 1), 
R+         byrow = TRUE, nrow = 3), name = "state t3")
R> mcCCRC <- new("markovchainList",markovchains = list(Q0,Q1,Q2,Q3), 
R+       name = "Continuous Care Health Community")
R> print(mcCCRC)
\end{CodeInput}

\begin{CodeOutput}
Continuous Care Health Community  list of Markov chain(s) 
Markovchain  1 
state t0 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 H, I, D 
 The transition matrix  (by rows)  is defined as follows: 
    H   I   D
H 0.7 0.2 0.1
I 0.1 0.6 0.3
D 0.0 0.0 1.0

Markovchain  2 
state t1 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 H, I, D 
 The transition matrix  (by rows)  is defined as follows: 
    H   I   D
H 0.5 0.3 0.2
I 0.0 0.4 0.6
D 0.0 0.0 1.0

Markovchain  3 
state t2 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 H, I, D 
 The transition matrix  (by rows)  is defined as follows: 
    H   I   D
H 0.3 0.2 0.5
I 0.0 0.2 0.8
D 0.0 0.0 1.0

Markovchain  4 
state t3 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 H, I, D 
 The transition matrix  (by rows)  is defined as follows: 
  H I D
H 0 0 1
I 0 0 1
D 0 0 1
\end{CodeOutput}
\end{CodeChunk}

It is possible to perform direct access to \texttt{markovchainList} elements, as well as to determine the number of \texttt{markovchain} objects by which a \texttt{markovchainList} object is composed.

\begin{CodeChunk}

\begin{CodeInput}
R> mcCCRC[[1]]
\end{CodeInput}

\begin{CodeOutput}
state t0 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 H, I, D 
 The transition matrix  (by rows)  is defined as follows: 
    H   I   D
H 0.7 0.2 0.1
I 0.1 0.6 0.3
D 0.0 0.0 1.0
\end{CodeOutput}

\begin{CodeInput}
R> dim(mcCCRC)
\end{CodeInput}

\begin{CodeOutput}
[1] 4
\end{CodeOutput}
\end{CodeChunk}

The \texttt{markovchain} package contains some data found in the literature related to DTMC models (see Section \ref{sec:applications}. Table \ref{tab:datasets} lists datasets and tables included within the current release of the package.

\begin{table}[h]
  \centering
  \begin{tabular}{p{0.2\textwidth}p{0.75\textwidth}}
  \hline
  Dataset & Description \\
 \hline  \hline
  \code{blanden} & Mobility across income quartiles, \cite{blandenEtAlii}.\\
  \code{craigsendi} & CD4 cells, \cite{craigSendi}.\\
  \code{kullback} & raw transition matrices for testing homogeneity, \cite{kullback1962tests}.\\
  \code{preproglucacon} & Preproglucacon DNA basis, \cite{averyHenderson}.\\
  \code{rain} & Alofi Island rains, \cite{averyHenderson}.\\
  \code{holson} & Individual states trajectiories.\\
  \code{sales} & Sales of six beverages in Hong Kong \cite{ching2008higher}. \\
\hline
\end{tabular}
\caption{The \pkg{markovchain} \code{data.frame} and \code{table}.}
\label{tab:datasets}
\end{table}

Finally, Table \ref{tab:demos} lists the demos included in the demo directory of the package.

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \hline
  R Code Filee & Description \\
    \hline  \hline
    \code{bard.R} & Structural analysis of Markov chains from Bard PPT.\\
    \code{examples.R} & Notable Markov chains, e.g., The Gambler Ruin chain.\\
    \code{quickStart.R} & Generic examples.\\
    \code{extractMatrices.R} & Generic examples.\\
\hline
\end{tabular}
\caption{The \pkg{markovchain} demos.}
\label{tab:demos}
\end{table}

\hypertarget{sec:probability}{%
\section{Probability with markovchain objects}\label{sec:probability}}

The \pkg{markovchain} package contains functions to analyse DTMC from a probabilistic perspective. For example, the package provides methods to find stationary distributions and identifying absorbing and transient states. Many of these methods come from \proglang{MATLAB} listings that have been ported into \proglang{R}. For a full description of the underlying theory and algorithm the interested reader can overview the original \proglang{MATLAB} listings, \cite{renaldoMatlab} and \cite{montgomery}.

Table \ref{tab:methodsToStats} shows methods that can be applied on \texttt{markovchain} objects to perform probabilistic analysis.

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \hline
  Method & Returns \\
    \hline  \hline
  \code{absorbingStates} & the absorbing states of the transition
  matrix, if any.\\
  \code{steadyStates} & the vector(s) of steady state(s) in matrix form. \\
  \code{meanFirstPassageTime} & matrix or vector of mean first passage times. \\
  \code{meanRecurrenceTime} & vector of mean number of steps to return to each recurrent state \\
  \code{hittingProbabilities} & matrix of hitting probabilities for a Markov chain. \\ 
  \code{meanAbsorptionTime} & expected number of steps for a transient state to be \\
                            & absorbed by any recurrent class \\
  \code{absorptionProbabilities} & probabilities of transient states of being \\
                                 & absorbed by each recurrent state \\
  \code{committorAB} & committor probabilities \\
  \code{communicatingClasses} & list of communicating classes. \\
   & $s_{j}$, given actual state $s_{i}$. \\
  \code{canonicForm} & the transition matrix into canonic form. \\
  \code{is.accessible} & checks whether a state j is reachable from state i. \\
  \code{is.irreducible} & checks whether a DTMC is irreducible. \\
  \code{is.regular} & checks whether a DTMC is regular. \\
  \code{period} & the period of an irreducible DTMC. \\
  \code{recurrentClasses} & list of recurrent communicating classes. \\
  \code{transientClasses} & list of transient communicatingclasses. \\
  \code{recurrentStates} & the recurrent states of the transition matrix. \\
  \code{transientStates} & the transient states of the transition matrix, if any. \\
  \code{summary} & DTMC summary. \\
  \hline
  \end{tabular}
\caption{\pkg{markovchain} methods: statistical operations.}
\label{tab:methodsToStats}
\end{table}

\hypertarget{conditional-distributions}{%
\subsection{Conditional distributions}\label{conditional-distributions}}

The conditional distribution of weather states, given that current day's weather
is sunny, is given by following code.

\begin{CodeChunk}

\begin{CodeInput}
R> conditionalDistribution(mcWeather, "sunny")
\end{CodeInput}

\begin{CodeOutput}
 sunny cloudy   rain 
   0.7    0.2    0.1 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{stationary-states}{%
\subsection{Stationary states}\label{stationary-states}}

A stationary (steady state, or equilibrium) vector is a probability vector such that Equation \ref{eq:steadystat2} holds

\begin{equation}
\begin{matrix}
0\leq \pi_j \leq 1\\ 
\sum_{j \in S} \pi_j = 1\\ 
\pi \cdot P = \pi
\end{matrix}
\label{eq:steadystat2}
\end{equation}

Steady states are associated to \(P\) eigenvalues equal to one. We could be tempted to compute them
solving the eigen values / vectors of the matrix and taking real parts (since if \(u + iv\) is a eigen vector, for the matrix \(P\), then \(Re(u + iv) = u\) and \(Im(u + iv) = v\) are eigen vectors) and normalizing by the vector sum, this carries some concerns:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If \(u, v \in \mathbb{R}^n\) are linearly independent eigen vectors associated to \(1\) eigen value, \(u + iv\), \(u + iu\) are also linearly independent eigen vectors, and their real parts coincide. Clearly if we took real parts, we would be loosing an eigen vector, because we cannot know in advance if the underlying algorithm to compute the eigen vectors is going to output something similar to what we described. We should be agnostic to the underlying eigen vector computation algorithm.
\item
  Imagine the identity \(P\) of dimensions \(2 \times 2\). Its eigen vectors associated to the \(1\) eigen value are \(u = (1, 0)\) and \(v = (0, 1)\). However, the underlying algorithm to compute eigen vectors could return \((1, -2)\) and \((-2, 1)\) instead, that are linear combinations of the aforementioned ones, and therefore eigen vectors. Normalizing by their sum, we would get: \((-1, 2)\) and \((2, -1)\), which obviously are not probability measures. Again, we should be agnostic to the underlying eigen computation algorithm.
\item
  Algorithms to compute eigen values / vectors are computationally expensive: they are iterative, and we cannot predict a fixed number of iterations for them. Moreover, each iteration takes \(\mathcal{O}(m^2)\) or \(\mathcal{O}(m^3)\) algorithmic complexity, with \(m\) the number of states.
\end{enumerate}

We are going to use that every irreducible DTMC has a unique steady state, that is, if \(M\) is the matrix for an irreducible DTMC (all states communicate with each other), then it exists a unique \(v \in \mathbb{R}^m\) such that:

\[ v \cdot M = v, \qquad \sum_{i = 1}^m v_i = 1 \]

Also, we'll use that a steady state for a DTMC assigns \(0\) to the transient states. The cannonic form of a (by row) stochastic matrix looks alike:

\[
\left(\begin{array}{c|c|c|c|c}
M_1 & 0 & 0 & \ldots & 0 \\
\hline
0 & M_2 & 0 & \ldots & 0 \\
\hline
0 & 0 & M_3 & \ldots & 0 \\
\hline
\vdots & \vdots & \vdots & \ddots & \vdots \\
\hline
A_1 & A_2 & A_3 & \ldots & R
\end{array}\right)
\]

where \(M_i\) corresponds to irreducible subchains, the blocks \(A_i\) correspond to the transitions from transient states to each of the recurrent classes and \(R\) are the transitions from the transient states to themselves.

Also, we should note that a Markov chain has exactly the same name of steady states as recurrent classes. Therefore, we have coded the following algorithm \footnote{We would like to thank Prof.~Christophe Dutang for his contributions to the development of this method. He coded a first improvement of the original \texttt{steadyStates} method and we could not have reached the current correctness without his previous work}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the recurrent classes \([C_1, \ldots, C_l]\) with \texttt{recurrentClasses} function.
\item
  Take each class \(C_i\), compute the submatrix corresponding to it \(M_i\).
\item
  Solve the system \(v \cdot C_i = v, \, \sum_{j = 1}^{|C_i|} v_j = 1\) which has a unique solution, for each \(i = 1, \ldots, l\).
\item
  Map each state \(v_i\) to the oiginal order in \(P\) and assign a \(0\) to the slots corresponding to transient states in the matrix.
\end{enumerate}

The result is returned in matrix form.

\begin{CodeChunk}

\begin{CodeInput}
R> steadyStates(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
         sunny    cloudy      rain
[1,] 0.4636364 0.3181818 0.2181818
\end{CodeOutput}
\end{CodeChunk}

It is possible for a Markov chain to have more than one stationary distribution, as the gambler ruin example shows.

\begin{CodeChunk}

\begin{CodeInput}
R> gamblerRuinMarkovChain <- function(moneyMax, prob = 0.5) {
R+   m <- matlab::zeros(moneyMax + 1)
R+   m[1,1] <- m[moneyMax + 1,moneyMax + 1] <- 1
R+   states <- as.character(0:moneyMax)
R+   rownames(m) <- colnames(m) <- states
R+   
R+   for(i in 2:moneyMax){ 
R+     m[i,i-1] <- 1 - prob
R+     m[i, i + 1] <- prob   
R+   }
R+   
R+   new("markovchain", transitionMatrix = m, 
R+       name = paste("Gambler ruin", moneyMax, "dim", sep = " "))
R+ }
R> 
R> mcGR4 <- gamblerRuinMarkovChain(moneyMax = 4, prob = 0.5)
R> steadyStates(mcGR4)
\end{CodeInput}

\begin{CodeOutput}
     0 1 2 3 4
[1,] 0 0 0 0 1
[2,] 1 0 0 0 0
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{classification-of-states}{%
\subsection{Classification of states}\label{classification-of-states}}

Absorbing states are determined by means of \texttt{absorbingStates} method.

\begin{CodeChunk}

\begin{CodeInput}
R> absorbingStates(mcGR4)
\end{CodeInput}

\begin{CodeOutput}
[1] "0" "4"
\end{CodeOutput}

\begin{CodeInput}
R> absorbingStates(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
character(0)
\end{CodeOutput}
\end{CodeChunk}

The key function in methods which need knowledge about communicating classes, recurrent states, transient
states, is \texttt{.commclassKernel}, which is a modification of Tarjan's algorithm from \cite{Tarjan}. This
\texttt{.commclassKernel} method gets a transition matrix of dimension \(n\) and returns a list of two items:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{classes}, an matrix whose \((i, j)\) entry is \texttt{true} iff \(s_i\) and \(s_j\) are in the same communicating class.
\item
  \texttt{closed}, a vector whose \(i\) -th entry indicates whether the communicating class to which \(i\) belongs is closed.
\end{enumerate}

These functions are used by two other internal functions on which the \texttt{summary} method for \texttt{markovchain} objects works.

The example matrix used in \cite{renaldoMatlab} well exemplifies the purpose of the function.

\begin{CodeChunk}

\begin{CodeInput}
R> P <- matlab::zeros(10)
R> P[1, c(1, 3)] <- 1/2;
R> P[2, 2] <- 1/3; P[2,7] <- 2/3;
R> P[3, 1] <- 1;
R> P[4, 5] <- 1;
R> P[5, c(4, 5, 9)] <- 1/3;
R> P[6, 6] <- 1;
R> P[7, 7] <- 1/4; P[7,9] <- 3/4;
R> P[8, c(3, 4, 8, 10)] <- 1/4;
R> P[9, 2] <- 1;
R> P[10, c(2, 5, 10)] <- 1/3;
R> rownames(P) <- letters[1:10] 
R> colnames(P) <- letters[1:10]
R> probMc <- new("markovchain", transitionMatrix = P, 
R+               name = "Probability MC")
R> summary(probMc)
\end{CodeInput}

\begin{CodeOutput}
Probability MC  Markov chain that is composed by: 
Closed classes: 
a c 
b g i 
f 
Recurrent classes: 
{a,c},{b,g,i},{f}
Transient classes: 
{d,e},{h},{j}
The Markov chain is not irreducible 
The absorbing states are: f
\end{CodeOutput}
\end{CodeChunk}

All states that pertain to a transient class are named ``transient'' and a
specific method has been written to elicit them.

\begin{CodeChunk}

\begin{CodeInput}
R> transientStates(probMc)
\end{CodeInput}

\begin{CodeOutput}
[1] "d" "e" "h" "j"
\end{CodeOutput}
\end{CodeChunk}

\texttt{canonicForm} method that turns a Markov chain into its canonic form, reordering the states to have first the
recurrent classes and then the transient states.

\begin{CodeChunk}

\begin{CodeInput}
R> probMcCanonic <- canonicForm(probMc)
R> probMc
\end{CodeInput}

\begin{CodeOutput}
Probability MC 
 A  10 - dimensional discrete Markov Chain defined by the following states: 
 a, b, c, d, e, f, g, h, i, j 
 The transition matrix  (by rows)  is defined as follows: 
    a         b    c         d         e f         g    h         i         j
a 0.5 0.0000000 0.50 0.0000000 0.0000000 0 0.0000000 0.00 0.0000000 0.0000000
b 0.0 0.3333333 0.00 0.0000000 0.0000000 0 0.6666667 0.00 0.0000000 0.0000000
c 1.0 0.0000000 0.00 0.0000000 0.0000000 0 0.0000000 0.00 0.0000000 0.0000000
d 0.0 0.0000000 0.00 0.0000000 1.0000000 0 0.0000000 0.00 0.0000000 0.0000000
e 0.0 0.0000000 0.00 0.3333333 0.3333333 0 0.0000000 0.00 0.3333333 0.0000000
f 0.0 0.0000000 0.00 0.0000000 0.0000000 1 0.0000000 0.00 0.0000000 0.0000000
g 0.0 0.0000000 0.00 0.0000000 0.0000000 0 0.2500000 0.00 0.7500000 0.0000000
h 0.0 0.0000000 0.25 0.2500000 0.0000000 0 0.0000000 0.25 0.0000000 0.2500000
i 0.0 1.0000000 0.00 0.0000000 0.0000000 0 0.0000000 0.00 0.0000000 0.0000000
j 0.0 0.3333333 0.00 0.0000000 0.3333333 0 0.0000000 0.00 0.0000000 0.3333333
\end{CodeOutput}

\begin{CodeInput}
R> probMcCanonic
\end{CodeInput}

\begin{CodeOutput}
Probability MC 
 A  10 - dimensional discrete Markov Chain defined by the following states: 
 a, c, b, g, i, f, d, e, h, j 
 The transition matrix  (by rows)  is defined as follows: 
    a    c         b         g         i f         d         e    h         j
a 0.5 0.50 0.0000000 0.0000000 0.0000000 0 0.0000000 0.0000000 0.00 0.0000000
c 1.0 0.00 0.0000000 0.0000000 0.0000000 0 0.0000000 0.0000000 0.00 0.0000000
b 0.0 0.00 0.3333333 0.6666667 0.0000000 0 0.0000000 0.0000000 0.00 0.0000000
g 0.0 0.00 0.0000000 0.2500000 0.7500000 0 0.0000000 0.0000000 0.00 0.0000000
i 0.0 0.00 1.0000000 0.0000000 0.0000000 0 0.0000000 0.0000000 0.00 0.0000000
f 0.0 0.00 0.0000000 0.0000000 0.0000000 1 0.0000000 0.0000000 0.00 0.0000000
d 0.0 0.00 0.0000000 0.0000000 0.0000000 0 0.0000000 1.0000000 0.00 0.0000000
e 0.0 0.00 0.0000000 0.0000000 0.3333333 0 0.3333333 0.3333333 0.00 0.0000000
h 0.0 0.25 0.0000000 0.0000000 0.0000000 0 0.2500000 0.0000000 0.25 0.2500000
j 0.0 0.00 0.3333333 0.0000000 0.0000000 0 0.0000000 0.3333333 0.00 0.3333333
\end{CodeOutput}
\end{CodeChunk}

The function \texttt{is.accessible} permits to investigate whether a state \(s_{j}\) is accessible from state \(s_i\), that is whether the probability to eventually reach \(s_j\) starting from \(s_{i}\) is greater than zero.

\begin{CodeChunk}

\begin{CodeInput}
R> is.accessible(object = probMc, from = "a", to = "c")
\end{CodeInput}

\begin{CodeOutput}
[1] TRUE
\end{CodeOutput}

\begin{CodeInput}
R> is.accessible(object = probMc, from = "g", to = "c")
\end{CodeInput}

\begin{CodeOutput}
[1] FALSE
\end{CodeOutput}
\end{CodeChunk}

In Section \ref{sec:properties} we observed that, if a DTMC is irreducible, all its states share the same periodicity. Then, the \texttt{period} function returns the periodicity of the DTMC, provided that it is irreducible. The example that follows shows how to find if a DTMC is reducible or irreducible by means of the function \texttt{is.irreducible} and, in the latter case, the method \texttt{period} is used to compute the periodicity of the chain.

\begin{CodeChunk}

\begin{CodeInput}
R> E <- matrix(0, nrow = 4, ncol = 4)
R> E[1, 2] <- 1
R> E[2, 1] <- 1/3; E[2, 3] <- 2/3
R> E[3,2] <- 1/4; E[3, 4] <- 3/4
R> E[4, 3] <- 1
R> 
R> mcE <- new("markovchain", states = c("a", "b", "c", "d"), 
R+      transitionMatrix = E, 
R+      name = "E")
R> is.irreducible(mcE)
\end{CodeInput}

\begin{CodeOutput}
[1] TRUE
\end{CodeOutput}

\begin{CodeInput}
R> period(mcE)
\end{CodeInput}

\begin{CodeOutput}
[1] 2
\end{CodeOutput}
\end{CodeChunk}

The example Markov chain found in \proglang{Mathematica} web site \citep{mathematica9MarkovChain} has
been used, and is plotted in Figure \ref{fig:mcMathematics}.

\begin{CodeChunk}

\begin{CodeInput}
R> require(matlab)
R> mathematicaMatr <- zeros(5)
R> mathematicaMatr[1,] <- c(0, 1/3, 0, 2/3, 0)
R> mathematicaMatr[2,] <- c(1/2, 0, 0, 0, 1/2)
R> mathematicaMatr[3,] <- c(0, 0, 1/2, 1/2, 0)
R> mathematicaMatr[4,] <- c(0, 0, 1/2, 1/2, 0)
R> mathematicaMatr[5,] <- c(0, 0, 0, 0, 1)
R> statesNames <- letters[1:5]
R> mathematicaMc <- new("markovchain", transitionMatrix = mathematicaMatr,
R+                    name = "Mathematica MC", states = statesNames)
\end{CodeInput}
\end{CodeChunk}

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{/tmp/RtmpghR4s0/file36246af82052/articles/an_introduction_to_markovchain_package_files/figure-latex/mcMathematics-1} 

}

\caption[Mathematica 9 example]{Mathematica 9 example. Markov chain plot.}\label{fig:mcMathematics}
\end{figure}
\end{CodeChunk}

\begin{CodeChunk}

\begin{CodeOutput}
Mathematica MC  Markov chain that is composed by: 
Closed classes: 
c d 
e 
Recurrent classes: 
{c,d},{e}
Transient classes: 
{a,b}
The Markov chain is not irreducible 
The absorbing states are: e
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{first-passage-time-distributions-and-means}{%
\subsection{First passage time distributions and means}\label{first-passage-time-distributions-and-means}}

\cite{renaldoMatlab} provides code to compute first passage time (within \(1,2,\ldots, n\) steps) given the initial state to be \(i\). The \proglang{MATLAB} listings translated into \proglang{R} on which the \texttt{firstPassage} function is based are:

\begin{CodeChunk}

\begin{CodeInput}
R> .firstpassageKernel <- function(P, i, n){
R>   G <- P
R>   H <- P[i,]
R>   E <- 1 - diag(size(P)[2])
R>   for (m in 2:n) {
R>     G <- P %*% (G * E)
R>     H <- rbind(H, G[i,])
R>   }
R>   return(H)
R> }
\end{CodeInput}
\end{CodeChunk}

We conclude that the probability for the \emph{first} rainy day to be the third one, given that the current state is sunny, is given by:

\begin{CodeChunk}

\begin{CodeInput}
R> firstPassagePdF <- firstPassage(object = mcWeather, state = "sunny", 
R+                                 n = 10)
R> firstPassagePdF[3, 3]
\end{CodeInput}

\begin{CodeOutput}
[1] 0.121
\end{CodeOutput}
\end{CodeChunk}

To compute the \emph{mean} first passage times, i.e.~the expected number of days before it rains
given that today is sunny, we can use the \texttt{meanFirstPassageTime} function:

\begin{CodeChunk}

\begin{CodeInput}
R> meanFirstPassageTime(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
          sunny   cloudy     rain
sunny  0.000000 4.285714 6.666667
cloudy 3.725490 0.000000 5.000000
rain   4.117647 2.857143 0.000000
\end{CodeOutput}
\end{CodeChunk}

indicating e.g.~that the average numer of days of sun or cloud before rain is 6.67 if we start
counting from a sunny day, and 5 if we start from a cloudy day. Note that
we can also specify one or more destination states:

\begin{CodeChunk}

\begin{CodeInput}
R> meanFirstPassageTime(mcWeather,"rain")
\end{CodeInput}

\begin{CodeOutput}
   sunny   cloudy 
6.666667 5.000000 
\end{CodeOutput}
\end{CodeChunk}

The implementation follows the matrix solutions by \citep{GrinsteadSnell}. We can check the result by averaging the first passage probability density function:

\begin{CodeChunk}

\begin{CodeInput}
R> firstPassagePdF.long <- firstPassage(object = mcWeather, state = "sunny",  n = 100)
R> sum(firstPassagePdF.long[,"rain"] * 1:100)
\end{CodeInput}

\begin{CodeOutput}
[1] 6.666664
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{mean-recurrence-time}{%
\subsection{Mean recurrence time}\label{mean-recurrence-time}}

The \texttt{meanRecurrenceTime} method gives the first mean recurrence time (expected number of steps to go back to a state if it was the initial one) for each recurrent state in the transition probabilities matrix for a DTMC. Let's see an example:

\begin{CodeChunk}

\begin{CodeInput}
R> meanRecurrenceTime(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
   sunny   cloudy     rain 
2.156863 3.142857 4.583333 
\end{CodeOutput}
\end{CodeChunk}

Another example, with not all of its states being recurrent:

\begin{CodeChunk}

\begin{CodeInput}
R> recurrentStates(probMc)
\end{CodeInput}

\begin{CodeOutput}
[1] "a" "b" "c" "f" "g" "i"
\end{CodeOutput}

\begin{CodeInput}
R> meanRecurrenceTime(probMc)
\end{CodeInput}

\begin{CodeOutput}
       f        b        g        i        a        c 
1.000000 2.555556 2.875000 3.833333 1.500000 3.000000 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{absorption-probabilities-and-mean-absorption-time}{%
\subsection{Absorption probabilities and mean absorption time}\label{absorption-probabilities-and-mean-absorption-time}}

We are going to use the Drunkard's random walk from \citep{GrinsteadSnell}. We have a drunk person walking through the street. Each move the person does, if they have not arrived to either home (corner 1) or to the bar (corner 5) could be to the left corner or to the right one, with equal probability. In case of arrival to the bar or to home, the person stays there.

\begin{CodeChunk}

\begin{CodeInput}
R> drunkProbs <- matlab::zeros(5, 5)
R> drunkProbs[1,1] <- drunkProbs[5,5] <- 1
R> drunkProbs[2,1] <- drunkProbs[2,3] <- 1/2
R> drunkProbs[3,2] <- drunkProbs[3,4] <- 1/2
R> drunkProbs[4,3] <- drunkProbs[4,5] <- 1/2
R> 
R> drunkMc <- new("markovchain", transitionMatrix = drunkProbs)
R> drunkMc
\end{CodeInput}

\begin{CodeOutput}
Unnamed Markov chain 
 A  5 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3, 4, 5 
 The transition matrix  (by rows)  is defined as follows: 
    1   2   3   4   5
1 1.0 0.0 0.0 0.0 0.0
2 0.5 0.0 0.5 0.0 0.0
3 0.0 0.5 0.0 0.5 0.0
4 0.0 0.0 0.5 0.0 0.5
5 0.0 0.0 0.0 0.0 1.0
\end{CodeOutput}
\end{CodeChunk}

Recurrent (in fact absorbing states) are:

\begin{CodeChunk}

\begin{CodeInput}
R> recurrentStates(drunkMc)
\end{CodeInput}

\begin{CodeOutput}
[1] "1" "5"
\end{CodeOutput}
\end{CodeChunk}

Transient states are the rest:

\begin{CodeChunk}

\begin{CodeInput}
R> transientStates(drunkMc)
\end{CodeInput}

\begin{CodeOutput}
[1] "2" "3" "4"
\end{CodeOutput}
\end{CodeChunk}

The probability of either being absorbed by the bar or by the sofa at home are:

\begin{CodeChunk}

\begin{CodeInput}
R> absorptionProbabilities(drunkMc)
\end{CodeInput}

\begin{CodeOutput}
     1    5
2 0.75 0.25
3 0.50 0.50
4 0.25 0.75
\end{CodeOutput}
\end{CodeChunk}

which means that the probability of arriving home / bar is inversely proportional to the distance to each one.

But we also would like to know how much time does the person take to arrive there, which can be done with \texttt{meanAbsorptionTime}:

\begin{CodeChunk}

\begin{CodeInput}
R> meanAbsorptionTime(drunkMc)
\end{CodeInput}

\begin{CodeOutput}
2 3 4 
3 4 3 
\end{CodeOutput}
\end{CodeChunk}

So it would take \texttt{3} steps to arrive to the destiny if the person is either in the second or fourth corner, and \texttt{4} steps in case of being at the same distance from home than to the bar.

\hypertarget{committor-probability}{%
\subsection{Committor probability}\label{committor-probability}}

The committor probability tells us the probability to reach a given state before another given.
Suppose that we start in a cloudy day, the probabilities of experiencing a rainy day before
a sunny one is 0.5:

\begin{CodeChunk}

\begin{CodeInput}
R> committorAB(mcWeather,3,1)
\end{CodeInput}

\begin{CodeOutput}
 sunny cloudy   rain 
   0.0    0.5    1.0 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{hitting-probabilities}{%
\subsection{Hitting probabilities}\label{hitting-probabilities}}

Rewriting the system \eqref{eq:hitting-probs} as:

\begin{equation*}
A = \left(\begin{array}{c|c|c|c}
  A_1 & 0 & \ldots & 0 \\
\hline
  0 & A_2 & \ldots & 0 \\
\hline
  \vdots & \vdots & \ddots & 0 \\
\hline
  0 & 0 & \ldots & A_n
\end{array}\right)
\end{equation*}

\begin{eqnarray*}
A_1 &= 
\left(\begin{matrix}
  -1     & p_{1,2}       & p_{1,3}   & \ldots & p_{1,n} \\
  0      & (p_{2,2} - 1) & p_{2,3}   & \ldots & p_{2,n} \\
  \vdots & \vdots        & \vdots    & \ddots & \vdots  \\
  0      & p_{n, 2}      & p_{n,3}   & \ldots & (p_{n,n} - 1)
  \end{matrix}\right)\\
A_2 &= \left(\begin{matrix}
  (p_{1,1} - 1) & 0      & p_{1,3}   & \ldots & p_{1,n} \\
  p_{2,1}       & -1     & p_{2,3}   & \ldots & p_{2,n} \\
  \vdots        & \vdots & \vdots    & \ddots & \vdots  \\
  p_{n,1}       & 0      & p_{n,3}   & \ldots & (p_{n,n} - 1)
  \end{matrix}\right)\\
\vdots & \vdots\\
A_n &= \left(\begin{matrix}
  (p_{1,1} - 1) & p_{1,2}      & p_{1,3}   & \ldots & 0 \\
  p_{2,1}       & (p_{2,2} -1) & p_{2,3}   & \ldots & 0 \\
  \vdots        & \vdots       & \vdots    & \ddots & \vdots  \\
  p_{n,1}       & p_{n,2}      & p_{n,3}   & \ldots & -1
  \end{matrix}\right)\\
\end{eqnarray*}

\begin{equation*}
\begin{array}{lr}
X_j = \left(\begin{array}{c}
h_{1,j} \\
h_{2,j} \\
\vdots  \\
h_{n,j}
\end{array}\right) &
C_j = - \left(\begin{array}{c}
p_{1,j} \\
p_{2,j} \\
\vdots  \\
p_{n,j}
\end{array}\right)
\end{array}
\end{equation*}

we end up having to solve the block systems:

\begin{equation}
A_j \cdot X_j = C_j
\end{equation}

Let us imagine the \(i\) -th state has transition probabilities: \((0, \ldots, 0, \underset{i)}{1}, 0, \ldots, 0)\). Then that same row would turn into \((0,0, \ldots, 0)\) for some block, thus obtaining a singular matrix. Another case which may give us problems could be: state \(i\) has the following transition probabilities: \((0, \ldots, 0, \underset{j)}{1}, 0, \ldots, 0)\) and the state \(j\) has the following transition probabilities: \((0, \ldots, 0, \underset{i)}{1}, 0, \ldots, 0)\). Then when builing some blocks we will end up with rows:

\begin{eqnarray*}
(0, \ldots, 0, \underset{i)}{-1}, 0, \ldots, 0, \underset{j)}{1}, 0, \ldots, 0) \\
(0, \ldots, 0, \underset{i)}{1},  0, \ldots, 0, \underset{j)}{-1}, 0, \ldots, 0)
\end{eqnarray*}

which are linearly dependent. Our hypothesis is that if we treat the closed communicating classes differently, we \emph{might} delete the linearity in the system. If we have a closed communicating class \(C_u\), then \(h_{i,j} = 1\) for all \(i,j \in C_u\) and \(h_{k,j} = 0\) for all \(k\not\in C_u\). Then we can set \(X_u\) appropriately and solve the other \(X_v\) using those values.

The method in charge of that in \texttt{markovchain} package is \texttt{hittingProbabilities}, which receives a Markov chain and computes the matrix \((h_{ij})_{i,j = 1,\ldots, n}\) where \(S = \{s_1, \ldots, s_n\}\) is the set of all states of the chain.

For the following chain:

\begin{CodeChunk}

\begin{CodeInput}
R> M <- matlab::zeros(5, 5)
R> M[1,1] <- M[5,5] <- 1
R> M[2,1] <- M[2,3] <- 1/2
R> M[3,2] <- M[3,4] <- 1/2
R> M[4,2] <- M[4,5] <- 1/2
R> 
R> hittingTest <- new("markovchain", transitionMatrix = M)
R> hittingProbabilities(hittingTest)
\end{CodeInput}

\begin{CodeOutput}
    1     2     3         4   5
1 1.0 0.000 0.000 0.0000000 0.0
2 0.8 0.375 0.500 0.3333333 0.2
3 0.6 0.750 0.375 0.6666667 0.4
4 0.4 0.500 0.250 0.1666667 0.6
5 0.0 0.000 0.000 0.0000000 1.0
\end{CodeOutput}
\end{CodeChunk}

we want to compute the hitting probabilities. That can be done with:

\begin{CodeChunk}

\begin{CodeInput}
R> hittingProbabilities(hittingTest)
\end{CodeInput}

\begin{CodeOutput}
    1     2     3         4   5
1 1.0 0.000 0.000 0.0000000 0.0
2 0.8 0.375 0.500 0.3333333 0.2
3 0.6 0.750 0.375 0.6666667 0.4
4 0.4 0.500 0.250 0.1666667 0.6
5 0.0 0.000 0.000 0.0000000 1.0
\end{CodeOutput}
\end{CodeChunk}

In the case of the \texttt{mcWeather} Markov chain we would obtain a matrix with all its elements set to \(1\). That makes sense (and is desirable) since if today is sunny, we expect it would be sunny again at certain point in the time, and the same with rainy weather (that way we assure good harvests):

\begin{CodeChunk}

\begin{CodeInput}
R> hittingProbabilities(mcWeather)
\end{CodeInput}

\begin{CodeOutput}
       sunny cloudy rain
sunny      1      1    1
cloudy     1      1    1
rain       1      1    1
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{sec:statistics}{%
\section{Statistical analysis}\label{sec:statistics}}

Table \ref{tab:funs4Stats} lists the functions and methods implemented within the package which help to fit, simulate and predict DTMC.

\begin{table}[h]
  \centering
  \begin{tabular}{lll}
    \hline
  Function & Purpose \\
    \hline  \hline
  \code{markovchainFit} & Function to return fitted Markov chain for a given sequence.\\
  \code{predict} & Method to calculate predictions from \code{markovchain} or
   \\
    & \code{markovchainList} objects.\\
   \code{rmarkovchain} & Function to sample from \code{markovchain} or \code{markovchainList} objects.\\
    \hline
\end{tabular}
\caption{The \pkg{markovchain} statistical functions.}
\label{tab:funs4Stats}
\end{table}

\hypertarget{simulation}{%
\subsection{Simulation}\label{simulation}}

Simulating a random sequence from an underlying DTMC is quite easy thanks to the function \texttt{rmarkovchain}. The following code generates a year of weather states according to \texttt{mcWeather} underlying stochastic process.

\begin{CodeChunk}

\begin{CodeInput}
R> weathersOfDays <- rmarkovchain(n = 365, object = mcWeather, t0 = "sunny")
R> weathersOfDays[1:30]
\end{CodeInput}

\begin{CodeOutput}
 [1] "sunny"  "sunny"  "cloudy" "rain"   "cloudy" "rain"   "cloudy" "sunny" 
 [9] "sunny"  "sunny"  "cloudy" "sunny"  "cloudy" "rain"   "cloudy" "cloudy"
[17] "sunny"  "sunny"  "cloudy" "rain"   "cloudy" "rain"   "cloudy" "sunny" 
[25] "rain"   "rain"   "cloudy" "rain"   "cloudy" "sunny" 
\end{CodeOutput}
\end{CodeChunk}

Similarly, it is possible to simulate one or more sequences from a non-homogeneous Markov chain,
as the following code (applied on CCHC example) exemplifies.

\begin{CodeChunk}

\begin{CodeInput}
R> patientStates <- rmarkovchain(n = 5, object = mcCCRC, t0 = "H", 
R+                               include.t0 = TRUE)
R> patientStates[1:10,]
\end{CodeInput}

\begin{CodeOutput}
   iteration values
1          1      H
2          1      H
3          1      I
4          1      I
5          1      D
6          2      H
7          2      D
8          2      D
9          2      D
10         2      D
\end{CodeOutput}
\end{CodeChunk}

Two advance parameters are availabe to the \texttt{rmarkovchain} method which helps you decide which implementation to use. There are four options available : \proglang{R}, \proglang{R} in parallel, \proglang{C++} and \proglang{C++} in parallel. Two boolean parameters \texttt{useRcpp} and \texttt{parallel} will decide which implementation will be used. Default is \code{useRcpp = TRUE} and \code{parallel = FALSE} i.e. \proglang{C++} implementation. The \proglang{C++} implementation is generally faster than the \texttt{R} implementation. If you have multicore processors then you can take advantage of \texttt{parallel} parameter by setting it to \texttt{TRUE}. When both \texttt{Rcpp=TRUE} and \texttt{parallel=TRUE} the parallelization has been carried out using \pkg{RcppParallel} package \citep{pkg:RcppParallel}.

\hypertarget{estimation}{%
\subsection{Estimation}\label{estimation}}

A time homogeneous Markov chain can be fit from given data. Four methods have been implemented within current version of \pkg{markovchain} package: maximum likelihood, maximum likelihood with Laplace smoothing, Bootstrap approach, maximum a posteriori.

Equation \ref{eq:MLE} shows the maximum likelihood estimator (MLE) of the \(p_{ij}\) entry, where the \(n_{ij}\) element consists in the number sequences \(\left( X_{t}=s_{i}, X_{t+1}=s_{j}\right)\) found in the sample, that is

\begin{equation}
{\hat p^{MLE}}_{ij} = \frac{n_{ij}}{\sum\limits_{u = 1}^k {n_{iu}}}.
\label{eq:MLE}
\end{equation}

Equation \eqref{eq:SE} shows the \texttt{standardError} of the MLE \citep{MSkuriat}.

\begin{equation}
SE_{ij} = \frac{ {\hat p^{MLE}}_{ij} }{\sqrt{n_{ij}}}
\label{eq:SE}
\end{equation}

\begin{CodeChunk}

\begin{CodeInput}
R> weatherFittedMLE <- markovchainFit(data = weathersOfDays, method = "mle",name = "Weather MLE")
R> weatherFittedMLE$estimate
\end{CodeInput}

\begin{CodeOutput}
Weather MLE 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 cloudy, rain, sunny 
 The transition matrix  (by rows)  is defined as follows: 
          cloudy       rain     sunny
cloudy 0.2924528 0.38679245 0.3207547
rain   0.5063291 0.27848101 0.2151899
sunny  0.1955307 0.08938547 0.7150838
\end{CodeOutput}

\begin{CodeInput}
R> weatherFittedMLE$standardError
\end{CodeInput}

\begin{CodeOutput}
           cloudy       rain      sunny
cloudy 0.05252608 0.06040683 0.05500898
rain   0.08005766 0.05937235 0.05219121
sunny  0.03305073 0.02234637 0.06320508
\end{CodeOutput}
\end{CodeChunk}

The Laplace smoothing approach is a variation of the MLE, where the \(n_{ij}\)
is substituted by \(n_{ij}+\alpha\) (see Equation \ref{eq:LAPLACE}), being
\(\alpha\) an arbitrary positive stabilizing parameter.

\begin{equation}
{\hat p^{LS}}_{ij} = \frac{{{n_{ij}} + \alpha }}{{\sum\limits_{u = 1}^k {\left( {{n_{iu}} + \alpha } \right)} }}
\label{eq:LAPLACE}
\end{equation}

\begin{CodeChunk}

\begin{CodeInput}
R> weatherFittedLAPLACE <- markovchainFit(data = weathersOfDays, 
R+                                     method = "laplace", laplacian = 0.01,
R+                                     name = "Weather LAPLACE")
R> weatherFittedLAPLACE$estimate
\end{CodeInput}

\begin{CodeOutput}
Weather LAPLACE 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 cloudy, rain, sunny 
 The transition matrix  (by rows)  is defined as follows: 
          cloudy       rain     sunny
cloudy 0.2924644 0.38677733 0.3207583
rain   0.5062634 0.27850183 0.2152347
sunny  0.1955538 0.08942635 0.7150198
\end{CodeOutput}
\end{CodeChunk}

(NOTE: The Confidence Interval option is enabled by default. Remove this option to fasten computations.) Both MLE and Laplace approach are based on the \texttt{createSequenceMatrix} functions that returns the raw counts transition matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> createSequenceMatrix(stringchar = weathersOfDays)
\end{CodeInput}

\begin{CodeOutput}
       cloudy rain sunny
cloudy     31   41    34
rain       40   22    17
sunny      35   16   128
\end{CodeOutput}
\end{CodeChunk}

\texttt{stringchar} could contain \texttt{NA} values, and the transitions containing \texttt{NA} would be ignored.

An issue occurs when the sample contains only one realization of a state (say \(X_{\beta}\)) which is located at the end of the data sequence, since it yields to a row of zero (no sample to estimate the conditional distribution of the transition). In this case the estimated transition matrix is corrected assuming \(p_{\beta,j}=1/k\), being \(k\) the possible states.

Create sequence matrix can also be used to obtain raw count transition matrices from a given \(n*2\) matrix as the following example shows:

\begin{CodeChunk}

\begin{CodeInput}
R> myMatr<-matrix(c("a","b","b","a","a","b","b","b","b","a","a","a","b","a"),ncol=2)
R> createSequenceMatrix(stringchar = myMatr,toRowProbs = TRUE)
\end{CodeInput}

\begin{CodeOutput}
          a         b
a 0.6666667 0.3333333
b 0.5000000 0.5000000
\end{CodeOutput}
\end{CodeChunk}

A bootstrap estimation approach has been developed within the package in order
to provide an indication of the variability of \({\hat p}_{ij}\) estimates. The
bootstrap approach implemented within the \pkg{markovchain} package follows
these steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  bootstrap the data sequences following the conditional distributions of states estimated from the original one. The default bootstrap samples is 10, as specified in \texttt{nboot} parameter of \texttt{markovchainFit} function.
\item
  apply MLE estimation on bootstrapped data sequences that are saved in \texttt{bootStrapSamples} slot of the returned list.
\item
  the \({p^{BOOTSTRAP}}_{ij}\) is the average of all \({p^{MLE}}_{ij}\) across the \texttt{bootStrapSamples} list, normalized by row. A \texttt{standardError} of \(\hat{{p^{MLE}}_{ij}}\) estimate is provided as well.
\end{enumerate}

\begin{CodeChunk}

\begin{CodeInput}
R> weatherFittedBOOT <- markovchainFit(data = weathersOfDays, 
R+                                     method = "bootstrap", nboot = 20)
R> weatherFittedBOOT$estimate
\end{CodeInput}

\begin{CodeOutput}
BootStrap Estimate 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 cloudy, rain, sunny 
 The transition matrix  (by rows)  is defined as follows: 
          cloudy       rain     sunny
cloudy 0.3120962 0.38177545 0.3061284
rain   0.5064550 0.26754824 0.2259968
sunny  0.1926384 0.08669469 0.7206669
\end{CodeOutput}

\begin{CodeInput}
R> weatherFittedBOOT$standardError
\end{CodeInput}

\begin{CodeOutput}
            cloudy       rain       sunny
cloudy 0.010710839 0.01147667 0.008964407
rain   0.012566526 0.01093224 0.012802794
sunny  0.006500678 0.00360786 0.006795080
\end{CodeOutput}
\end{CodeChunk}

The bootstrapping process can be done in parallel thanks to \pkg{RcppParallel} package \citep{pkg:RcppParallel}. Parallelized implementation is definitively suggested when the data sample size or the required number of bootstrap runs is high.

\begin{CodeChunk}

\begin{CodeInput}
R> weatherFittedBOOTParallel <- markovchainFit(data = weathersOfDays, 
R>                                     method = "bootstrap", nboot = 200, 
R>                                     parallel = TRUE)
R> weatherFittedBOOTParallel$estimate
R> weatherFittedBOOTParallel$standardError
\end{CodeInput}
\end{CodeChunk}

The parallel bootstrapping uses all the available cores on a machine by default.
However, it is also possible to tune the number of threads used.
Note that this should be done in R before calling the \texttt{markovchainFit} function.
For example, the following code will set the number of threads to 4.

\begin{CodeChunk}

\begin{CodeInput}
R> RcppParallel::setNumThreads(2)
\end{CodeInput}
\end{CodeChunk}

For more details, please refer to \pkg{RcppParallel} web site.

For all the fitting methods, the \texttt{logLikelihood} \citep{MSkuriat} denoted in Equation \ref{eq:LLH} is provided.

\begin{equation}
LLH = \sum_{i,j} n_{ij} * log (p_{ij})
\label{eq:LLH}
\end{equation}
where \(n_{ij}\) is the entry of the frequency matrix and \(p_{ij}\) is the entry of the transition probability matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> weatherFittedMLE$logLikelihood
\end{CodeInput}

\begin{CodeOutput}
[1] -335.8655
\end{CodeOutput}

\begin{CodeInput}
R> weatherFittedBOOT$logLikelihood
\end{CodeInput}

\begin{CodeOutput}
[1] -336.0256
\end{CodeOutput}
\end{CodeChunk}

Confidence matrices of estimated parameters (parametric for MLE, non - parametric for BootStrap) are available as well. The \texttt{confidenceInterval} is provided with the two matrices: \texttt{lowerEndpointMatrix} and \texttt{upperEndpointMatrix}. The confidence level (CL) is 0.95 by default and can be given as an argument of the function \texttt{markovchainFit}. This is used to obtain the standard score (z-score). From classical inference theory, if \(ci\) is the level of confidence required assuming normal distribution the \(zscore(ci)\) solves \(\Phi \left ( 1-\left(\frac{1-ci}{2}\right) \right )\)
Equations \ref{eq:CIL} and \ref{eq:CIU} \citep{MSkuriat} show the \texttt{confidenceInterval} of a fitting. Note that each entry of the matrices is bounded between 0 and 1.

\begin{align}
LowerEndpoint_{ij} = p_{ij} - zscore (CL) * SE_{ij} \label{eq:CIL} \\
UpperEndpoint_{ij} = p_{ij} + zscore (CL) * SE_{ij}
\label{eq:CIU}
\end{align}

\begin{CodeChunk}

\begin{CodeInput}
R> weatherFittedMLE$confidenceInterval
\end{CodeInput}

\begin{CodeOutput}
NULL
\end{CodeOutput}

\begin{CodeInput}
R> weatherFittedBOOT$confidenceInterval
\end{CodeInput}

\begin{CodeOutput}
$confidenceLevel
[1] 0.95

$lowerEndpointMatrix
          cloudy       rain     sunny
cloudy 0.2944784 0.36289801 0.2913833
rain   0.4857849 0.24956630 0.2049381
sunny  0.1819457 0.08076029 0.7094900

$upperEndpointMatrix
          cloudy       rain     sunny
cloudy 0.3297139 0.40065289 0.3208735
rain   0.5271251 0.28553017 0.2470555
sunny  0.2033311 0.09262909 0.7318438
\end{CodeOutput}
\end{CodeChunk}

A special function, \texttt{multinomialConfidenceIntervals}, has been written in order to obtain multinomial wise confidence intervals. The code has been based on and Rcpp translation of package's \pkg{MultinomialCI} functions \cite{pkg:MultinomialCI} that were themselves based on the \cite{sison1995simultaneous} paper.

\begin{CodeChunk}

\begin{CodeInput}
R> multinomialConfidenceIntervals(transitionMatrix = 
R+         weatherFittedMLE$estimate@transitionMatrix, 
R+         countsTransitionMatrix = createSequenceMatrix(weathersOfDays))
\end{CodeInput}

\begin{CodeOutput}
$confidenceLevel
[1] 0.95

$lowerEndpointMatrix
          cloudy       rain     sunny
cloudy 0.1981132 0.29245283 0.2264151
rain   0.4050633 0.17721519 0.1139241
sunny  0.1340782 0.02793296 0.6536313

$upperEndpointMatrix
          cloudy      rain     sunny
cloudy 0.4020523 0.4963920 0.4303542
rain   0.6311157 0.4032676 0.3399765
sunny  0.2627732 0.1566279 0.7823263
\end{CodeOutput}
\end{CodeChunk}

The functions for fitting DTMC have mostly been rewritten in \proglang{C++} using \pkg{Rcpp} \cite{RcppR} since version 0.2.

It is also possible to fit a DTMC object from \texttt{matrix} or \texttt{data.frame} objects as shown in following code.

\begin{CodeChunk}

\begin{CodeInput}
R> data(holson)
R> singleMc<-markovchainFit(data=holson[,2:12],name="holson")
\end{CodeInput}
\end{CodeChunk}

The same applies for \texttt{markovchainList}.

\begin{CodeChunk}

\begin{CodeInput}
R> mcListFit<-markovchainListFit(data=holson[,2:6],name="holson")
R> mcListFit$estimate
\end{CodeInput}

\begin{CodeOutput}
holson  list of Markov chain(s) 
Markovchain  1 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  2 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  3 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  4 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  5 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  6 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  7 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  8 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  9 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  10 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  11 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  12 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  13 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.5000000 0.5000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  14 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  15 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  16 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 0.7500000 0.2500000 0.0000000

Markovchain  17 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  18 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  19 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  20 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  21 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  22 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  23 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  24 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  25 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  26 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.7500000 0.2500000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  27 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  28 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  29 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  30 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  31 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  32 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  33 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  34 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  35 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  36 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  37 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 0 1
2 0 1

Markovchain  38 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  39 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  40 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  41 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  42 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  43 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  44 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  45 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  46 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  47 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  48 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  49 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  50 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  51 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  52 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  53 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  54 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  55 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  56 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  57 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  58 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  59 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  60 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  61 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  62 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  63 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  64 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  65 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  66 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  67 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  68 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  69 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  70 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  71 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  72 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  73 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  74 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  75 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  76 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  77 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  78 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  79 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  80 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  81 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  82 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  83 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  84 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  85 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  86 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  87 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  88 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6666667 0.3333333
2 0.0000000 0.5000000 0.5000000
3 0.3333333 0.3333333 0.3333333

Markovchain  89 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  90 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  91 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  92 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  93 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  94 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  95 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  96 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  97 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  98 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.75 0.25
2 1.00 0.00

Markovchain  99 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  100 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  101 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  102 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  103 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  104 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  105 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  106 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  107 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  108 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  109 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  110 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  111 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  112 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  113 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.7500000 0.2500000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  114 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  115 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  116 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  117 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  118 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  119 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.6666667 0.3333333 0.0000000
3 0.0000000 1.0000000 0.0000000

Markovchain  120 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  121 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  122 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 2 
 The transition matrix  (by rows)  is defined as follows: 
  2
2 1

Markovchain  123 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  124 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  125 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  126 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  127 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  128 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  129 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  130 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  131 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  132 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.8 0.2
3 0.5 0.5

Markovchain  133 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.7500000 0.2500000 0.0000000
2 0.3333333 0.3333333 0.3333333
3 1.0000000 0.0000000 0.0000000

Markovchain  134 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  135 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  136 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  137 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  138 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.6666667 0.0000000
2 0.0000000 0.5000000 0.5000000
3 0.3333333 0.3333333 0.3333333

Markovchain  139 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 0 0 1
2 0 0 1
3 0 0 1

Markovchain  140 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.6000000 0.4000000 0.0000000

Markovchain  141 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  142 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  143 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  144 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  145 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  146 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  147 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  148 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  149 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  150 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.2000000 0.4000000 0.4000000

Markovchain  151 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  152 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  153 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  154 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  155 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.6000000 0.4000000 0.0000000

Markovchain  156 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  157 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  158 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  159 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  160 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  161 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  162 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  163 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  164 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  165 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  166 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  167 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  168 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  169 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  170 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  171 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  172 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  173 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  174 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  175 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  176 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  177 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  178 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  179 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  180 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  181 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  182 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  183 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  184 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.2 0.8

Markovchain  185 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
     2    3
2 0.00 1.00
3 0.75 0.25

Markovchain  186 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 0 1
3 0 1

Markovchain  187 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  188 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  189 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  190 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.2 0.8

Markovchain  191 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 0 1
3 0 1

Markovchain  192 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  193 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  194 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  195 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  196 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  197 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  198 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  199 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  200 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  201 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  202 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  203 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  204 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  205 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  206 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  207 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  208 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.75 0.25
2 1.00 0.00

Markovchain  209 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  210 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  211 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  212 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  213 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  214 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  215 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  216 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  217 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  218 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  219 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  220 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  221 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  222 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  223 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  224 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  225 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  226 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  227 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  228 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  229 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  230 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  231 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  232 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  233 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  234 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  235 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  236 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  237 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.2000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  238 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  239 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  240 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  241 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  242 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  243 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  244 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  245 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  246 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  247 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  248 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  249 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  250 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  251 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  252 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 0.0 1.0

Markovchain  253 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  254 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  255 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  256 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.6000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  257 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  258 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.4000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  259 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  260 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  261 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  262 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  263 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  264 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  265 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.8000000 0.2000000 0.0000000

Markovchain  266 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  267 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  268 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 0.6666667 0.3333333
2 0.5000000 0.5000000

Markovchain  269 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  270 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  271 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  272 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  273 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  274 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  275 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.7500000 0.2500000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  276 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  277 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  278 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.0 1.0
3 0.5 0.5

Markovchain  279 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  280 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  281 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  282 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  283 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  284 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  285 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  286 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.6666667 0.0000000
3 0.0000000 1.0000000 0.0000000

Markovchain  287 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  288 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  289 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  290 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  291 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  292 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 0 1
2 0 1

Markovchain  293 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  294 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  295 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 1.0000000 0.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  296 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
     2    3
2 1.00 0.00
3 0.75 0.25

Markovchain  297 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  298 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  299 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  300 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  301 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  302 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  303 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  304 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  305 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  306 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  307 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  308 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2500000 0.7500000 0.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  309 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  310 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  311 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  312 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  313 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 0 1
3 0 1

Markovchain  314 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.6 0.4

Markovchain  315 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  316 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  317 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  318 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  319 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  320 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  321 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  322 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  323 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  324 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 0 1
3 0 1

Markovchain  325 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  326 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  327 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  328 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  329 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  330 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  331 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  332 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  333 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  334 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  335 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 0 1
2 1 0

Markovchain  336 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2500000 0.7500000
2 0.0000000 1.0000000 0.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  337 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.5000000 0.5000000 0.0000000
3 0.0000000 0.6666667 0.3333333

Markovchain  338 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2 3
1 0.0000000 1.0000000 0
2 0.6666667 0.3333333 0
3 1.0000000 0.0000000 0

Markovchain  339 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  340 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  341 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  342 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  343 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  344 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  345 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  346 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  347 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  348 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 0 1
3 0 1

Markovchain  349 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  350 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  351 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  352 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  353 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 0 1
2 0 1

Markovchain  354 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 0.4 0.6

Markovchain  355 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 1.0000000 0.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  356 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          2         3
2 1.0000000 0.0000000
3 0.6666667 0.3333333

Markovchain  357 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.2500000 0.7500000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  358 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  359 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  360 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  361 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.2 0.8

Markovchain  362 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 0.2500000 0.7500000 0.0000000

Markovchain  363 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 1.0000000 0.0000000
2 0.6666667 0.3333333

Markovchain  364 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  365 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  366 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  367 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 1.0 0.0

Markovchain  368 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  369 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  370 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  371 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  372 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.4000000 0.4000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  373 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   2 3
1 0.5 0.5 0
2 1.0 0.0 0
3 1.0 0.0 0

Markovchain  374 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.25 0.75
2 0.00 1.00

Markovchain  375 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.00 1.00
2 0.75 0.25

Markovchain  376 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.3333333 0.6666667
2 0.5000000 0.5000000 0.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  377 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  378 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  379 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.4000000 0.4000000 0.2000000

Markovchain  380 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  381 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  382 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  383 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  384 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  385 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  386 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  387 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  388 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  389 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  390 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  391 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.2 0.8

Markovchain  392 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  393 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  394 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  395 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  396 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  397 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  398 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  399 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  400 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 2 
 The transition matrix  (by rows)  is defined as follows: 
  2
2 1

Markovchain  401 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  402 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  403 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  404 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  405 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  406 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  407 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  408 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 0.0 1.0

Markovchain  409 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.5000000 0.5000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  410 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1   2   3
1 1 0.0 0.0
2 0 1.0 0.0
3 0 0.5 0.5

Markovchain  411 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  412 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  413 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  414 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.6000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  415 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 0 1 0
2 0 1 0
3 0 0 1

Markovchain  416 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 1 0
3 1 0

Markovchain  417 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.2 0.8
3 0.5 0.5

Markovchain  418 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  419 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  420 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  421 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  422 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  423 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.75 0.25
2 0.00 1.00

Markovchain  424 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  425 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.5000000 0.5000000
3 0.3333333 0.3333333 0.3333333

Markovchain  426 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  427 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  428 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  429 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  430 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  431 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  432 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  433 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  434 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  435 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  436 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  437 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  438 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  439 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  440 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  441 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  442 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  443 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  444 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  445 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  446 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  447 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  448 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  449 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  450 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  451 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  452 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  453 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  454 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  455 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  456 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  457 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  458 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.5000000 0.5000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  459 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  460 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  461 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  462 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  463 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  464 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  465 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  466 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  467 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 0.6666667 0.3333333
2 1.0000000 0.0000000

Markovchain  468 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 0 1

Markovchain  469 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  470 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  471 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  472 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  473 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  474 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2500000 0.5000000 0.2500000
2 0.0000000 1.0000000 0.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  475 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  476 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  477 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  478 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  479 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  480 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  481 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  482 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  483 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  484 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  485 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  486 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.00 1.00
2 0.25 0.75

Markovchain  487 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 1.0000000 0.0000000
2 0.0000000 0.5000000 0.5000000
3 0.3333333 0.3333333 0.3333333

Markovchain  488 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  489 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  490 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  491 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  492 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  493 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  494 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  495 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.6000000 0.2000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  496 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1         2         3
1 0 0.6666667 0.3333333
2 0 0.0000000 1.0000000
3 0 0.0000000 1.0000000

Markovchain  497 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  498 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  499 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.5000000 0.5000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  500 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  501 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  502 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  503 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  504 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  505 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  506 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  507 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.6000000 0.2000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  508 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  509 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  510 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  511 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  512 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  513 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  514 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  515 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  516 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  517 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.8 0.2
3 0.5 0.5

Markovchain  518 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 3
1 0 1
3 0 1

Markovchain  519 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  520 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  521 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  522 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  523 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  524 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  525 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 0.0000000 0.5000000 0.5000000

Markovchain  526 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   2 3
1 1.0 0.0 0
2 1.0 0.0 0
3 0.5 0.5 0

Markovchain  527 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.75 0.25
2 1.00 0.00

Markovchain  528 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 0 1
2 0 1

Markovchain  529 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  530 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  531 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  532 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  533 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  534 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  535 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  536 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.8000000 0.2000000 0.0000000

Markovchain  537 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  538 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  539 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  540 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  541 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  542 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  543 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  544 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  545 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  546 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  547 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  548 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  549 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  550 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  551 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  552 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  553 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.4000000 0.4000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  554 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  555 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  556 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  557 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  558 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  559 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  560 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  561 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  562 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  563 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  564 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  565 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  566 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  567 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  568 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 0.0 1.0

Markovchain  569 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  570 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  571 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  572 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  573 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  574 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  575 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  576 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  577 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  578 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  579 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  580 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  581 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  582 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  583 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  584 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  585 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  586 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  587 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  588 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.6000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  589 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  590 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  591 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.0000000 0.0000000 1.0000000
3 0.5000000 0.2500000 0.2500000

Markovchain  592 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  593 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  594 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  595 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  596 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  597 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  598 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  599 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  600 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  601 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  602 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  603 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  604 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  605 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  606 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  607 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  608 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  609 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  610 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  611 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  612 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  613 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  614 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  615 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  616 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 1.0 0.0

Markovchain  617 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.2500000 0.5000000 0.2500000
3 0.0000000 1.0000000 0.0000000

Markovchain  618 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  619 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  620 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  621 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  622 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 1.00 0.00
2 0.75 0.25

Markovchain  623 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  624 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  625 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  626 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  627 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  628 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  629 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  630 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  631 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  632 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  633 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  634 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  635 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  636 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.4000000 0.4000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  637 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  638 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  639 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 1 0
3 1 0

Markovchain  640 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  641 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  642 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  643 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  644 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.2000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  645 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  646 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  647 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  648 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  649 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  650 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  651 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  652 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  653 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  654 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.2 0.8
3 0.5 0.5

Markovchain  655 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  656 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  657 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  658 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  659 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  660 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  661 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 1.0000000 0.0000000
2 0.6666667 0.3333333

Markovchain  662 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  663 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  664 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  665 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  666 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  667 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  668 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  669 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  670 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  671 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  672 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  673 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  674 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  675 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  676 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  677 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  678 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  679 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  680 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  681 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  682 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  683 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  684 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  685 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  686 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  687 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  688 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  689 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  690 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  691 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  692 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  693 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  694 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2500000 0.5000000 0.2500000
2 0.0000000 1.0000000 0.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  695 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 0 1 0
2 0 1 0
3 1 0 0

Markovchain  696 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  697 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  698 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  699 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  700 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  701 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  702 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  703 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  704 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  705 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  706 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  707 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  708 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  709 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  710 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  711 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  712 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  713 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  714 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  715 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  716 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  717 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  718 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  719 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  720 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  721 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  722 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  723 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  724 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.4000000 0.4000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  725 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  726 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  727 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  728 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  729 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  730 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  731 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  732 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2500000 0.7500000 0.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  733 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  734 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  735 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  736 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  737 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  738 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  739 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  740 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  741 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  742 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  743 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  744 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.2 0.8

Markovchain  745 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  2 3
2 1 0
3 1 0

Markovchain  746 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  747 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  748 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  749 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  750 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  751 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  752 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  753 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  754 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  755 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  756 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  757 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  758 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  759 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  760 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  761 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 0.6666667 0.3333333
2 0.5000000 0.5000000

Markovchain  762 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  763 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  764 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 0.5000000 0.5000000
2 0.6666667 0.3333333

Markovchain  765 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  766 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  767 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  768 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  769 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  770 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  771 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.0000000 1.0000000 0.0000000
3 0.7500000 0.2500000 0.0000000

Markovchain  772 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 0.6666667 0.3333333
2 0.5000000 0.5000000

Markovchain  773 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  774 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  775 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  776 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  777 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  778 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 0 1
2 0 1

Markovchain  779 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.6 0.4
3 0.5 0.5

Markovchain  780 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          2         3
2 0.6666667 0.3333333
3 0.5000000 0.5000000

Markovchain  781 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  782 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  783 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  784 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  785 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  786 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  787 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  788 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  789 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  790 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  791 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  792 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  793 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  794 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  795 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  796 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  797 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  798 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  799 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  800 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  801 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  802 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  803 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  804 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  805 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  806 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.4000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  807 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  808 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  809 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  810 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.0 1.0
3 0.5 0.5

Markovchain  811 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  812 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  813 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  814 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  815 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  816 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  817 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  818 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  819 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  820 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  821 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  822 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  823 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  824 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  825 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  826 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  827 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  828 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  829 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  830 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  831 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  832 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  833 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  834 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.3333333 0.6666667
2 1.0000000 0.0000000 0.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  835 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  836 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  837 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.2000000 0.8000000 0.0000000

Markovchain  838 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  839 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  840 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  841 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2000000 0.6000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  842 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  843 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  844 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  845 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  846 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  847 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  848 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  849 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  850 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  851 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  852 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  853 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  854 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  855 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.8000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  856 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  857 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  858 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  859 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  860 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  861 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  862 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  863 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  864 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  865 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  866 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  867 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  868 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  869 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  870 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 1.0 0.0

Markovchain  871 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  872 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  873 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  874 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  875 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  876 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  877 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  878 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  879 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  880 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  881 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  882 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.75 0.25
2 1.00 0.00

Markovchain  883 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  884 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  885 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  886 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.4000000 0.4000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  887 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 0 1 0

Markovchain  888 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  889 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  890 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  891 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
          1         2
1 0.3333333 0.6666667
2 0.0000000 1.0000000

Markovchain  892 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  893 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.2 0.8
3 0.5 0.5

Markovchain  894 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 1.0000000 0.0000000
2 0.3333333 0.3333333 0.3333333
3 0.7500000 0.2500000 0.0000000

Markovchain  895 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  896 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 3 
 The transition matrix  (by rows)  is defined as follows: 
  3
3 1

Markovchain  897 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  898 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  899 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  900 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  901 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  902 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  903 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  904 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  905 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  906 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  907 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.5 0.5
2 0.8 0.2

Markovchain  908 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.0000000 1.0000000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  909 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 0.4000000 0.6000000 0.0000000

Markovchain  910 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  911 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  912 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  913 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  914 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  915 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  916 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  917 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  918 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.2500000 0.0000000 0.7500000
2 0.0000000 0.0000000 1.0000000
3 0.3333333 0.3333333 0.3333333

Markovchain  919 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 1.0000000 0.0000000 0.0000000
2 0.3333333 0.3333333 0.3333333
3 0.7500000 0.2500000 0.0000000

Markovchain  920 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  921 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.6000000 0.2000000 0.2000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  922 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 0 0 1
2 0 1 0
3 0 1 0

Markovchain  923 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.5000000 0.5000000 0.0000000
3 0.0000000 1.0000000 0.0000000

Markovchain  924 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  925 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  926 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  927 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  928 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
     1    2
1 0.75 0.25
2 1.00 0.00

Markovchain  929 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  930 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  931 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  932 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  933 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  934 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  935 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  936 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  937 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 1.0000000 0.0000000
2 0.0000000 0.2500000 0.7500000
3 0.3333333 0.3333333 0.3333333

Markovchain  938 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  939 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  940 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  941 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 0.3333333 0.3333333 0.3333333
3 1.0000000 0.0000000 0.0000000

Markovchain  942 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
  1 2 3
1 1 0 0
2 1 0 0
3 1 0 0

Markovchain  943 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.6 0.4
2 0.5 0.5

Markovchain  944 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  945 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  946 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  947 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  948 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  949 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  950 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  951 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.2 0.8
2 0.5 0.5

Markovchain  952 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  953 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.4 0.6
2 0.5 0.5

Markovchain  954 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  955 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.0 1.0
2 0.5 0.5

Markovchain  956 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.0 1.0
3 0.5 0.5

Markovchain  957 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  958 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  959 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  960 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  961 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  962 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  963 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  964 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  965 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  966 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  967 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  968 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.6000000 0.4000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  969 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  970 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  971 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  972 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
    1   2
1 0.8 0.2
2 0.5 0.5

Markovchain  973 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  974 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  975 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.4000000 0.6000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  976 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 0.6666667 0.3333333 0.0000000

Markovchain  977 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 2 
 The transition matrix  (by rows)  is defined as follows: 
  1 2
1 1 0
2 1 0

Markovchain  978 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  979 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
    2   3
2 0.5 0.5
3 0.4 0.6

Markovchain  980 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  981 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  982 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  983 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  984 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  985 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  986 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5

Markovchain  987 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.5 0.5
3 1.0 0.0

Markovchain  988 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  989 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  990 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  991 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  992 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  993 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  994 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  995 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  996 
Unnamed Markov chain 
 A  1 - dimensional discrete Markov Chain defined by the following states: 
 1 
 The transition matrix  (by rows)  is defined as follows: 
  1
1 1

Markovchain  997 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.0000000 0.2000000 0.8000000
2 0.3333333 0.3333333 0.3333333
3 0.3333333 0.3333333 0.3333333

Markovchain  998 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 1, 2, 3 
 The transition matrix  (by rows)  is defined as follows: 
          1         2         3
1 0.3333333 0.3333333 0.3333333
2 1.0000000 0.0000000 0.0000000
3 1.0000000 0.0000000 0.0000000

Markovchain  999 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 1, 3 
 The transition matrix  (by rows)  is defined as follows: 
    1   3
1 0.0 1.0
3 0.5 0.5
\end{CodeOutput}
\end{CodeChunk}

Finally, given a \texttt{list} object, it is possible to fit a \texttt{markovchain} object or to obtain the raw transition matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> c1<-c("a","b","a","a","c","c","a")
R> c2<-c("b")
R> c3<-c("c","a","a","c")
R> c4<-c("b","a","b","a","a","c","b")
R> c5<-c("a","a","c",NA)
R> c6<-c("b","c","b","c","a")
R> mylist<-list(c1,c2,c3,c4,c5,c6)
R> mylistMc<-markovchainFit(data=mylist)
R> mylistMc
\end{CodeInput}

\begin{CodeOutput}
$estimate
MLE Fit 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 a, b, c 
 The transition matrix  (by rows)  is defined as follows: 
    a         b         c
a 0.4 0.2000000 0.4000000
b 0.6 0.0000000 0.4000000
c 0.5 0.3333333 0.1666667


$standardError
          a         b         c
a 0.2000000 0.1414214 0.2000000
b 0.3464102 0.0000000 0.2828427
c 0.2886751 0.2357023 0.1666667

$confidenceLevel
[1] 0.95

$lowerEndpointMatrix
            a b           c
a 0.008007122 0 0.008007122
b 0.000000000 0 0.000000000
c 0.000000000 0 0.000000000

$upperEndpointMatrix
          a         b         c
a 0.7919929 0.4771808 0.7919929
b 1.0000000 0.0000000 0.9543616
c 1.0000000 0.7953014 0.4933274
\end{CodeOutput}
\end{CodeChunk}

The same works for \texttt{markovchainFitList}.

\begin{CodeChunk}

\begin{CodeInput}
R> markovchainListFit(data=mylist)
\end{CodeInput}

\begin{CodeOutput}
$estimate
  list of Markov chain(s) 
Markovchain  1 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 a, b, c 
 The transition matrix  (by rows)  is defined as follows: 
    a   b   c
a 0.5 0.5 0.0
b 0.5 0.0 0.5
c 1.0 0.0 0.0

Markovchain  2 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 a, b, c 
 The transition matrix  (by rows)  is defined as follows: 
          a         b         c
a 0.3333333 0.3333333 0.3333333
b 1.0000000 0.0000000 0.0000000
c 0.0000000 1.0000000 0.0000000

Markovchain  3 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 a, b, c 
 The transition matrix  (by rows)  is defined as follows: 
          a         b         c
a 0.5000000 0.0000000 0.5000000
b 0.5000000 0.0000000 0.5000000
c 0.3333333 0.3333333 0.3333333

Markovchain  4 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 a, c 
 The transition matrix  (by rows)  is defined as follows: 
    a   c
a 0.5 0.5
c 1.0 0.0

Markovchain  5 
Unnamed Markov chain 
 A  2 - dimensional discrete Markov Chain defined by the following states: 
 a, c 
 The transition matrix  (by rows)  is defined as follows: 
  a c
a 0 1
c 0 1

Markovchain  6 
Unnamed Markov chain 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 a, b, c 
 The transition matrix  (by rows)  is defined as follows: 
          a         b         c
a 0.3333333 0.3333333 0.3333333
b 0.3333333 0.3333333 0.3333333
c 0.5000000 0.5000000 0.0000000
\end{CodeOutput}
\end{CodeChunk}

If any transition contains \texttt{NA}, it will be ignored in the results as the above example showed.

\hypertarget{prediction}{%
\subsection{Prediction}\label{prediction}}

The \(n\)-step forward predictions can be obtained using the \texttt{predict} methods explicitly written for \texttt{markovchain} and \texttt{markovchainList} objects. The prediction is the mode of the conditional distribution of \(X_{t+1}\) given \(X_{t}=s_{j}\), being \(s_{j}\) the last realization of the DTMC (homogeneous or non-homogeneous).

\hypertarget{predicting-from-a-markovchain-object}{%
\subsubsection{Predicting from a markovchain object}\label{predicting-from-a-markovchain-object}}

The 3-days forward predictions from \texttt{markovchain} object can be generated as follows, assuming that the last two days were respectively ``cloudy'' and ``sunny''.

\begin{CodeChunk}

\begin{CodeInput}
R> predict(object = weatherFittedMLE$estimate, newdata = c("cloudy", "sunny"),
R+         n.ahead = 3)
\end{CodeInput}

\begin{CodeOutput}
[1] "sunny" "sunny" "sunny"
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{predicting-from-a-markovchainlist-object}{%
\subsubsection{Predicting from a markovchainList object}\label{predicting-from-a-markovchainlist-object}}

Given an initial two year Healty status, the 5-year ahead prediction of any CCRC guest is

\begin{CodeChunk}

\begin{CodeInput}
R> predict(mcCCRC, newdata = c("H", "H"), n.ahead = 5)
\end{CodeInput}

\begin{CodeOutput}
[1] "H" "D" "D"
\end{CodeOutput}
\end{CodeChunk}

The prediction has stopped at time sequence since the underlying non-homogeneous Markov chain has a length of four. In order to continue five years ahead, the \texttt{continue=TRUE} parameter setting makes the \texttt{predict} method keeping to use the last \texttt{markovchain} in the sequence list.

\begin{CodeChunk}

\begin{CodeInput}
R> predict(mcCCRC, newdata = c("H", "H"), n.ahead = 5, continue = TRUE)
\end{CodeInput}

\begin{CodeOutput}
[1] "H" "D" "D" "D" "D"
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{statistical-tests}{%
\subsection{Statistical Tests}\label{statistical-tests}}

In this section, we describe the statistical tests: assessing the Markov property (\texttt{verifyMarkovProperty}), the order (\texttt{assessOrder}), the statinarity (\texttt{assessStationarity}) of a Markov chain sequence, and the divergence test for empirically estimated transition matrices (\texttt{divergenceTest}). Most of such tests are based on the \(\chi ^2\) statistics. Relevand references are \cite{kullback1962tests} and \cite{anderson1957statistical}.

All such tests have been designed for small samples, since it is easy to detect departures from Markov property as long as the sample size increases. In addition, the accuracy of the statistical inference functions has been questioned and will be thoroughly investigated in future versions of the package.

\hypertarget{assessing-the-markov-property-of-a-markov-chain-sequence}{%
\subsubsection{Assessing the Markov property of a Markov chain sequence}\label{assessing-the-markov-property-of-a-markov-chain-sequence}}

The \texttt{verifyMarkovProperty} function verifies whether the Markov property holds for the given chain. The test implemented in the package looks at triplets of successive observations. If \(x_1, x_2, \ldots, x_N\) is a set of observations and \(n_{ijk}\) is the number of times \(t\) \(\left(1 \le t \le N-2 \right)\) such that \(x_t=i, x_{t+1}=j, x_{x+2}=k\), then if the Markov property holds \(n_{ijk}\) follows a Binomial distribution with parameters \(n_{ij}\) and \(p_{jk}\). A classical \(\chi^2\) test can check this distributional assumption, since \(\sum_{i}\sum_{j}\sum_{k}\frac{n_{ijk}-n_{ij}\hat{p_{jk}}}{n_{ij}\hat{p_{jk}}}\sim \chi^2\left(|S|^3 \right )\) where \(|S|\) is the cardinality of the state space.

\begin{CodeChunk}

\begin{CodeInput}
R> sample_sequence<-c("a", "b", "a", "a", "a", "a", "b", "a", "b", "a", 
R+                    "b", "a", "a", "b", "b", "b", "a")
R> verifyMarkovProperty(sample_sequence)
\end{CodeInput}

\begin{CodeOutput}
Warning in verifyMarkovProperty(sample_sequence): The accuracy of the
statistical inference functions has been questioned. It will be thoroughly
investigated in future versions of the package.
\end{CodeOutput}

\begin{CodeOutput}
Testing markovianity property on given data sequence
Chi - square statistic is: 0.28 
Degrees of freedom are: 8 
And corresponding p-value is: 0.9999857 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{assessing-the-order-of-a-markov-chain-sequence}{%
\subsubsection{Assessing the order of a Markov chain sequence}\label{assessing-the-order-of-a-markov-chain-sequence}}

The \texttt{assessOrder} function checks whether the given chain is of first order or of second order. For each possible present state, we construct a contingency table of the frequency of the future state for each past to present state transition as shown in Table \ref{tab:order}.

\begin{table}[h]
  \centering
  \begin{tabular}{l | l | l | l}
    \hline
  past & present & future & future \\
   &  & a & b \\
    \hline  \hline
  a & a & 2 & 2\\
  b & a & 2 & 2\\
  \hline
\end{tabular}
\caption{Contingency table to assess the order for the present state a.}
\label{tab:order}
\end{table}

Using the table, the function performs the \(\chi ^2\) test by calling the \texttt{chisq.test} function.
This test returns a list of the chi-squared value and the p-value. If the p-value is greater than the given significance level, we cannot reject the hypothesis that the sequence is of first order.

\begin{CodeChunk}

\begin{CodeInput}
R> data(rain)
R> assessOrder(rain$rain)
\end{CodeInput}

\begin{CodeOutput}
Warning in assessOrder(rain$rain): The accuracy of the statistical inference
functions has been questioned. It will be thoroughly investigated in future
versions of the package.
\end{CodeOutput}

\begin{CodeOutput}
The assessOrder test statistic is:  26.09575 
The Chi-Square d.f. are:  12 
The p-value is:  0.01040395 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{assessing-the-stationarity-of-a-markov-chain-sequence}{%
\subsubsection{Assessing the stationarity of a Markov chain sequence}\label{assessing-the-stationarity-of-a-markov-chain-sequence}}

The \texttt{assessStationarity} function assesses if the transition probabilities of the given chain change over time. To be more specific, the chain is stationary if the following condition meets.

\begin{equation}
p_{ij}(t) = p_{ij} ~\textrm{ for all }~t
\label{eq:stationarity}
\end{equation}

For each possible state, we construct a contingency table of the estimated transition probabilities over time as shown in Table \ref{tab:stationarity}.

\begin{table}[h]
  \centering
  \begin{tabular}{l | l | l}
    \hline
  time (t) & probability of transition to a & probability of transition to b \\
    \hline  \hline
  1 & 0 & 1\\
  2 & 0 & 1\\
  . & . & . \\
  . & . & . \\
  . & . & . \\
  16 & 0.44 & 0.56\\
  \hline
\end{tabular}
\caption{Contingency table to assess the stationarity of the state a.}
\label{tab:stationarity}
\end{table}

Using the table, the function performs the \(\chi ^2\) test by calling the \texttt{chisq.test} function.
This test returns a list of the chi-squared value and the p-value.
If the p-value is greater than the given significance level, we cannot reject the hypothesis that the sequence is stationary.

\begin{CodeChunk}

\begin{CodeInput}
R> assessStationarity(rain$rain, 10)
\end{CodeInput}

\begin{CodeOutput}
Warning in assessStationarity(rain$rain, 10): The accuracy of the statistical
inference functions has been questioned. It will be thoroughly investigated in
future versions of the package.
\end{CodeOutput}

\begin{CodeOutput}
Warning in chisq.test(mat): Chi-squared approximation may be incorrect
\end{CodeOutput}

\begin{CodeOutput}
Warning in chisq.test(mat): Chi-squared approximation may be incorrect
\end{CodeOutput}

\begin{CodeOutput}
Warning in chisq.test(mat): Chi-squared approximation may be incorrect
\end{CodeOutput}

\begin{CodeOutput}
The assessStationarity test statistic is:  4.181815 
The Chi-Square d.f. are:  54 
The p-value is:  1 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{divergence-tests-for-empirically-estimated-transition-matrices}{%
\subsubsection{Divergence tests for empirically estimated transition matrices}\label{divergence-tests-for-empirically-estimated-transition-matrices}}

This section discusses tests developed to verify whether:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  An empirical transition matrix is consistent with a theoretical one.\\
\item
  Two or more empirical transition matrices belongs to the same DTMC.
\end{enumerate}

The first test is implemented by the \texttt{verifyEmpiricalToTheoretical} function. Bein \(f_{ij}\) the raw transition count, \cite{kullback1962tests} shows that \(2*\sum_{i=1}^{r}\sum_{j=1}^{r}f_{ij}\ln\frac{f_{ij}}{f_{i.}P\left( E_j | E_i\right)} \sim \chi^2\left ( r*(r-1) \right )\). The following example is taken from \cite{kullback1962tests}:

\begin{CodeChunk}

\begin{CodeInput}
R> sequence<-c(0,1,2,2,1,0,0,0,0,0,0,1,2,2,2,1,0,0,1,0,0,0,0,0,0,1,1,
R+ 2,0,0,2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,2,1,0,
R+ 0,2,1,0,0,0,0,0,0,1,1,1,2,2,0,0,2,1,1,1,1,2,1,1,1,1,1,1,1,1,1,0,2,
R+ 0,1,1,0,0,0,1,2,2,0,0,0,0,0,0,2,2,2,1,1,1,1,0,1,1,1,1,0,0,2,1,1,
R+ 0,0,0,0,0,2,2,1,1,1,1,1,2,1,2,0,0,0,1,2,2,2,0,0,0,1,1)
R> mc=matrix(c(5/8,1/4,1/8,1/4,1/2,1/4,1/4,3/8,3/8),byrow=TRUE, nrow=3)
R> rownames(mc)<-colnames(mc)<-0:2; theoreticalMc<-as(mc, "markovchain")
R> verifyEmpiricalToTheoretical(data=sequence,object=theoreticalMc)
\end{CodeInput}

\begin{CodeOutput}
Warning in verifyEmpiricalToTheoretical(data = sequence, object =
theoreticalMc): The accuracy of the statistical inference functions has been
questioned. It will be thoroughly investigated in future versions of the
package.
\end{CodeOutput}

\begin{CodeOutput}
Testing whether the
   0  1  2
0 51 11  8
1 12 31  9
2  6 11 10
transition matrix is compatible with
      0     1     2
0 0.625 0.250 0.125
1 0.250 0.500 0.250
2 0.250 0.375 0.375
[1] "theoretical transition matrix"
ChiSq statistic is 6.551795 d.o.f are 6 corresponding p-value is 0.3642899 
\end{CodeOutput}

\begin{CodeOutput}
$statistic
       0 
6.551795 

$dof
[1] 6

$pvalue
        0 
0.3642899 
\end{CodeOutput}
\end{CodeChunk}

The second one is implemented by the \texttt{verifyHomogeneity} function, inspired by \cite[section~9]{kullback1962tests}. Assuming that \(i=1,2, \ldots, s\) DTMC samples are available and that the cardinality of the state space is \(r\) it verifies whether the \(s\) chains belongs to the same unknown one. \cite{kullback1962tests} shows that its test statistics follows a chi-square law, \(2*\sum_{i=1}^{s}\sum_{j=1}^{r}\sum_{k=1}^{r}f_{ijk}\ln\frac{n*f_{ijk}}{f_{i..}f_{.jk}} \sim \chi^2\left ( r*(r-1) \right )\). Also the following example is taken from \cite{kullback1962tests}:

\begin{CodeChunk}

\begin{CodeInput}
R> data(kullback)
R> verifyHomogeneity(inputList=kullback,verbose=TRUE)
\end{CodeInput}

\begin{CodeOutput}
Warning in verifyHomogeneity(inputList = kullback, verbose = TRUE): The
accuracy of the statistical inference functions has been questioned. It will be
thoroughly investigated in future versions of the package.
\end{CodeOutput}

\begin{CodeOutput}
Testing homogeneity of DTMC underlying input list 
ChiSq statistic is 275.9963 d.o.f are 35 corresponding p-value is 0 
\end{CodeOutput}

\begin{CodeOutput}
$statistic
[1] 275.9963

$dof
[1] 35

$pvalue
[1] 0
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{continuous-times-markov-chains}{%
\subsection{Continuous Times Markov Chains}\label{continuous-times-markov-chains}}

\hypertarget{intro}{%
\subsubsection{Intro}\label{intro}}

The \pkg{markovchain} package provides functionality for continuous time Markov chains (CTMCs). CTMCs are a generalisation of discrete time Markov chains (DTMCs) in that we allow time to be continuous. We assume a finite state space \(S\) (for an infinite state space wouldn't fit in memory). We can think of CTMCs as Markov chains in which state transitions can happen at any time.

More formally, we would like our CTMCs to satisfy the following two properties:

\begin{itemize}
\tightlist
\item
  The Markov property - let \(F_{X(s)}\) denote the information about \(X\) upto time \(s\). Let \(j \in S\) and \(s \leq t\). Then, \(P(X(t) = j|F_{X(s)}) = P(X(t) = j|X(s))\).
\item
  Time homogenity - \(P(X(t) = j|X(s) = k) = P(X(t-s) = j|X(0) = k)\).
\end{itemize}

If both the above properties are satisfied, it is referred to as a time-homogeneous CTMC. If a transition occurs at time \(t\), then \(X(t)\) denotes the new state and \(X(t)\neq X(t-)\).

Now, let \(X(0)=x\) and let \(T_x\) be the time a transition occurs from this state. We are interested in the distribution of \(T_x\). For \(s,t \geq 0\), it can be shown that \$ P(T\_x \textgreater{} s+t \textbar{} T\_x \textgreater{} s) = P(T\_x \textgreater{} t) \$

This is the memory less property that only the exponential random variable exhibits. Therefore, this is the sought distribution, and each state \(s \in S\) has an exponential holding parameter \(\lambda(s)\). Since \(\mathrm{E}T_x = \frac{1}{\lambda(x)}\), higher the rate \(\lambda(x)\), smaller the expected time of transitioning out of the state \(x\).

However, specifying this parameter alone for each state would only paint an incomplete picture of our CTMC. To see why, consider a state \(x\) that may transition to either state \(y\) or \(z\). The holding parameter enables us to predict when a transition may occur if we start off in state \(x\), but tells us nothing about which state will be next.

To this end, we also need transition probabilities associated with the process, defined as follows (for \(y \neq x\)) - \(p_{xy} = P(X(T_s) = y | X(0) = x)\). Note that \(\sum_{y \neq x} p_{xy} = 1\). Let \(Q\) denote this transition matrix (\(Q_{ij} = p_{ij}\)). What is key here is that \(T_x\) and the state \(y\) are independent random variables. Let's define \(\lambda(x, y) = \lambda(x) p_{xy}\)

We now look at Kolmogorov's backward equation. Let's define \(P_{ij}(t) = P(X(t) = j | X(0) = i)\) for \(i, j \in S\). The backward equation is given by (it can be proved) \(P_{ij}(t) = \delta_{ij}e^{-\lambda(i)t} + \int_{0}^{t}\lambda(i)e^{-\lambda(i)t} \sum_{k \neq i} Q_{ik} P_{kj}(t-s) ds\). Basically, the first term is non-zero if and only if \(i=j\) and represents the probability that the first transition from state \(i\) occurs after time \(t\). This would mean that at \(t\), the state is still \(i\). The second term accounts for any transitions that may occur before time \(t\) and denotes the probability that at time \(t\), when the smoke clears, we are in state \(j\).

This equation can be represented compactly as follows \(P'(t) = AP(t)\) where \(A\) is the \emph{generator} matrix.
\[
A(i, j) = \begin{cases} \lambda(i, j) & \mbox{if } i \neq j \\ -\lambda(i) & \mbox{else.} \end{cases}
\]
Observe that the sum of each row is 0. A CTMC can be completely specified by the generator matrix.

\hypertarget{stationary-distributions}{%
\subsubsection{Stationary Distributions}\label{stationary-distributions}}

The following theorem guarantees the existence of a unique stationary distribution for CTMCs. Note that \(X(t)\) being irreducible and recurrent is the same as \(X_n(t)\) being irreducible and recurrent.

Suppose that \(X(t)\) is irreducible and recurrent. Then \(X(t)\) has an invariant measure \(\eta\), which is unique up to multiplicative factors. Moreover, for each \(k \in S\), we have

\[\eta_k = \frac{\pi_k}{\lambda(k)}\]

where \(\pi\) is the unique invariant measure of the embedded discrete time Markov chain \(Xn\). Finally, \(\eta\) satisfies

\[0 < \eta_j < \infty, \forall j \in S\]

and if \(\sum_i \eta_i < \infty\) then \(\eta\) can be normalised to get a stationary distribution.

\hypertarget{estimation-1}{%
\subsubsection{Estimation}\label{estimation-1}}

Let the data set be \(D = \{(s_0, t_0), (s_1, t_1), ..., (s_{N-1}, t_{N-1})\}\) where \(N=|D|\). Each \(s_i\) is a state from the state space \(S\) and during the time \([t_i,t_{i+1}]\) the chain is in state \(s_i\). Let the parameters be represented by \(\theta = \{\lambda, P\}\) where \(\lambda\) is the vector of holding parameters for each state and \(P\) the transition matrix of the embedded discrete time Markov chain.

Then the probability is given by

\[
{Pr(D | \theta) \propto \lambda(s_0)e^{-\lambda(s_0)(t_1-t_0)}Pr(s_1|s_0) \cdot\ldots\cdot \lambda(s_{N-2})e^{-\lambda(s_{N-2})(t_{N-1}-t_{N-2})}Pr(s_{N-1}|s_{N-2})}
\]

Let \(n(j|i)\) denote the number of \(i\)-\textgreater{}\(j\) transitions in \(D\), and \(n(i)\) the number of times \(s_i\) occurs in \(D\). Let \(t(s_i)\) denote the total time the chain spends in state \(s_i\).

Then the MLEs are given by

\[
\hat{\lambda(s)} = \frac{n(s)}{t(s)},\hat{Pr(j|i)}=\frac{n(j|i)}{n(i)}
\]

\hypertarget{expected-hitting-time}{%
\subsubsection{Expected Hitting Time}\label{expected-hitting-time}}

The package provides a function \texttt{ExpectedTime} to calculate average hitting time from one state to another. Let the final state be j, then for every state \(i \in S\), where \(S\) is the set of all states and holding time \(q_{i} > 0\) for every \(i \neq j\). Assuming the conditions to be true, expected hitting time is equal to minimal non-negative solution vector \(p\) to the system of linear equations:
\begin{equation}
\begin{cases}
      p_{k} = 0 & k = j \\
      -\sum_{l \in I} q_{kl}p_{k} = 1 & k \neq j
\end{cases}
\label{eq:EHT}
\end{equation}

\hypertarget{probability-at-time-t}{%
\subsubsection{Probability at time t}\label{probability-at-time-t}}

The package provides a function \texttt{probabilityatT} to calculate probability of every state according to given \texttt{ctmc} object. Here we use Kolmogorov's backward equation \(P(t) = P(0)e^{tQ}\) for \(t \geq 0\) and \(P(0) = I\). Here \(P(t)\) is the transition function at time t. The value \(P(t)[i][j]\) at time \(P(t)\) describes the probability of the state at time \(t\) to be eqaul to j if it was equal to i at time \(t=0\).
It takes care of the case when \texttt{ctmc} object has a generator represented by columns.
If inital state is not provided, the function returns the whole transition matrix \(P(t)\).

\hypertarget{examples}{%
\subsubsection{Examples}\label{examples}}

To create a CTMC object, you need to provide a valid generator matrix, say \(Q\). The CTMC object has the following slots - states, generator, byrow, name (look at the documentation object for further details). Consider the following example in which we aim to model the transition of a molecule from the \(\sigma\) state to the \(\sigma^*\) state. When in the former state, if it absorbs sufficient energy, it can make the jump to the latter state and remains there for some time before transitioning back to the original state. Let us model this by a CTMC:

\begin{CodeChunk}

\begin{CodeInput}
R> energyStates <- c("sigma", "sigma_star")
R> byRow <- TRUE
R> gen <- matrix(data = c(-3, 3,
R+                        1, -1), nrow = 2,
R+               byrow = byRow, dimnames = list(energyStates, energyStates))
R> molecularCTMC <- new("ctmc", states = energyStates, 
R+                  byrow = byRow, generator = gen, 
R+                  name = "Molecular Transition Model")      
\end{CodeInput}
\end{CodeChunk}

To generate random CTMC transitions, we provide an initial distribution of the states. This must be in the same order as the dimnames of the generator. The output can be returned either as a list or a data frame.

\begin{CodeChunk}

\begin{CodeInput}
R> statesDist <- c(0.8, 0.2)
R> rctmc(n = 3, ctmc = molecularCTMC, initDist = statesDist, out.type = "df", include.T0 = FALSE)
\end{CodeInput}

\begin{CodeOutput}
      states             time
1 sigma_star 0.19816221188133
2      sigma 1.34390658865518
3 sigma_star 1.55347035324346
\end{CodeOutput}
\end{CodeChunk}

\(n\) represents the number of samples to generate. There is an optional argument \(T\) for \texttt{rctmc}. It represents the time of termination of the simulation. To use this feature, set \(n\) to a very high value, say \texttt{Inf} (since we do not know the number of transitions before hand) and set \(T\) accordingly.

\begin{CodeChunk}

\begin{CodeInput}
R> statesDist <- c(0.8, 0.2)
R> rctmc(n = Inf, ctmc = molecularCTMC, initDist = statesDist, T = 2)
\end{CodeInput}

\begin{CodeOutput}
[[1]]
[1] "sigma"      "sigma_star"

[[2]]
[1] 0.00000000 0.05237257
\end{CodeOutput}
\end{CodeChunk}

To obtain the stationary distribution simply invoke the \texttt{steadyStates} function

\begin{CodeChunk}

\begin{CodeInput}
R> steadyStates(molecularCTMC)
\end{CodeInput}

\begin{CodeOutput}
     sigma sigma_star
[1,]  0.25       0.75
\end{CodeOutput}
\end{CodeChunk}

For fitting, use the \texttt{ctmcFit} function. It returns the MLE values for the parameters along with the confidence intervals.

\begin{CodeChunk}

\begin{CodeInput}
R> data <- list(c("a", "b", "c", "a", "b", "a", "c", "b", "c"), 
R+              c(0, 0.8, 2.1, 2.4, 4, 5, 5.9, 8.2, 9))
R> ctmcFit(data)
\end{CodeInput}

\begin{CodeOutput}
$estimate
An object of class "ctmc"
Slot "states":
[1] "a" "b" "c"

Slot "byrow":
[1] TRUE

Slot "generator":
           a          b          c
a -0.9090909  0.6060606  0.3030303
b  0.3225806 -0.9677419  0.6451613
c  0.3846154  0.3846154 -0.7692308

Slot "name":
[1] ""


$errors
$errors$dtmcConfidenceInterval
$errors$dtmcConfidenceInterval$confidenceLevel
[1] 0.95

$errors$dtmcConfidenceInterval$lowerEndpointMatrix
  a b c
a 0 0 0
b 0 0 0
c 0 0 0

$errors$dtmcConfidenceInterval$upperEndpointMatrix
          a b         c
a 0.0000000 1 0.9866548
b 0.9866548 0 1.0000000
c 1.0000000 1 0.0000000


$errors$lambdaConfidenceInterval
$errors$lambdaConfidenceInterval$lowerEndpointVector
[1] 0.04576665 0.04871934 0.00000000

$errors$lambdaConfidenceInterval$upperEndpointVector
[1]  0.04576665  0.04871934 -0.12545166
\end{CodeOutput}
\end{CodeChunk}

One approach to obtain the generator matrix is to apply the \texttt{logm} function from the \pkg{expm} package on a transition matrix. Numeric issues arise, see \cite{israel2001finding}. For example, applying the standard \texttt{method} (`Higham08') on \texttt{mcWeather} raises an error, whilst the alternative method (eigenvalue decomposition) is ok. The following code estimates the generator matrix of the \texttt{mcWeather} transition matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> mcWeatherQ <- expm::logm(mcWeather@transitionMatrix,method='Eigen')
R> mcWeatherQ
\end{CodeInput}

\begin{CodeOutput}
           sunny     cloudy       rain
sunny  -0.863221   2.428723  -1.565502
cloudy  4.284592 -20.116312  15.831720
rain   -4.414019  24.175251 -19.761232
\end{CodeOutput}
\end{CodeChunk}

Therefore, the ``half - day'' transition probability for mcWeather DTMC is

\begin{CodeChunk}

\begin{CodeInput}
R> mcWeatherHalfDayTM <- expm::expm(mcWeatherQ*.5)
R> mcWeatherHalfDay <- new("markovchain",transitionMatrix=mcWeatherHalfDayTM,name="Half Day Weather Transition Matrix")
R> mcWeatherHalfDay
\end{CodeInput}

\begin{CodeOutput}
Half Day Weather Transition Matrix 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 sunny, cloudy, rain 
 The transition matrix  (by rows)  is defined as follows: 
            sunny    cloudy       rain
sunny  0.81598647 0.1420068 0.04200677
cloudy 0.21970167 0.4401492 0.34014916
rain   0.07063048 0.5146848 0.41468476
\end{CodeOutput}
\end{CodeChunk}

The \pkg{ctmcd} package \citep{pkg:ctmcd} provides various functions to estimate the generator matrix (GM) of a CTMC process using different methods. The following code provides a way to join \pkg{markovchain} and \pkg{ctmcd} computations.

\begin{CodeChunk}

\begin{CodeInput}
R> require(ctmcd)
\end{CodeInput}

\begin{CodeOutput}
Loading required package: ctmcd
\end{CodeOutput}

\begin{CodeInput}
R> require(expm)
\end{CodeInput}

\begin{CodeOutput}
Loading required package: expm
\end{CodeOutput}

\begin{CodeOutput}
Loading required package: Matrix
\end{CodeOutput}

\begin{CodeOutput}

Attaching package: 'expm'
\end{CodeOutput}

\begin{CodeOutput}
The following object is masked from 'package:Matrix':

    expm
\end{CodeOutput}

\begin{CodeInput}
R> #defines a function to transform a GM into a TM
R> gm_to_markovchain<-function(object, t=1) {
R+   if(!(class(object) %in% c("gm","matrix","Matrix")))
R+     stop("Error! Expecting either a matrix or a gm object")
R+   if ( class(object) %in% c("matrix","Matrix")) generator_matrix<-object else generator_matrix<-as.matrix(object[["par"]])
R+   #must add importClassesFrom("markovchain",markovchain) in the NAMESPACE
R+   #must add importFrom(expm, "expm")
R+   transitionMatrix<-expm(generator_matrix*t)
R+   out<-as(transitionMatrix,"markovchain")
R+   return(out)
R+ }
R> #loading ctmcd dataset
R> data(tm_abs)
R> gm0=matrix(1,8,8) #initializing
R> diag(gm0)=0
R> diag(gm0)=-rowSums(gm0)
R> gm0[8,]=0
R> gmem=gm(tm_abs,te=1,method="EM",gmguess=gm0) #estimating GM
R> mc_at_2=gm_to_markovchain(object=gmem, t=2) #converting to TM at time 2
\end{CodeInput}
\end{CodeChunk}

\hypertarget{pseudo---bayesian-estimation}{%
\subsection{Pseudo - Bayesian Estimation}\label{pseudo---bayesian-estimation}}

\cite{Hu2002} shows an empirical quasi-bayesian method to estimate transition matrices, given an empirical \(\hat{P}\) transition matrix (estimated using the classical approach) and an a - priori estimate \(Q\). In particular, each row of the matrix is estimated using the linear combination \(\alpha \cdot Q+\left(1-1alpha\right) \cdot P\), where \(\alpha\) is defined for each row as Equation \ref{eq:pseudobayes} shows

\begin{equation}
\left\{\begin{matrix}
\hat{\alpha_i}=\frac{\hat{K_i}}{v\left(i \right )+\hat{K_i}}\\ 
\hat{K_i}=\frac{v\left(i \right)^2 - \sum_{j}Y_{ij}^2}{\sum_{j}(Y_{ij}-v\left(i \right)*q_{ij})^2}
\end{matrix}\right.
\label{eq:pseudobayes}
\end{equation}

The following code returns the pseudo bayesian estimate of the transition matrix:

\begin{CodeChunk}

\begin{CodeInput}
R> pseudoBayesEstimator <- function(raw, apriori){
R+   v_i <- rowSums(raw) 
R+   K_i <- numeric(nrow(raw))
R+   sumSquaredY <- rowSums(raw^2)
R+   #get numerator
R+   K_i_num <- v_i^2-sumSquaredY
R+   #get denominator
R+   VQ <- matrix(0,nrow= nrow(apriori),ncol=ncol(apriori))
R+   for (i in 1:nrow(VQ)) {
R+     VQ[i,]<-v_i[i]*apriori[i,]
R+   }
R+   
R+   K_i_den<-rowSums((raw - VQ)^2)
R+   
R+   K_i <- K_i_num/K_i_den
R+   
R+   #get the alpha vector
R+   alpha <- K_i / (v_i+K_i)
R+   
R+   #empirical transition matrix
R+   Emp<-raw/rowSums(raw)
R+   
R+   #get the estimate
R+   out<-matrix(0, nrow= nrow(raw),ncol=ncol(raw))
R+   for (i in 1:nrow(out)) {
R+     out[i,]<-alpha[i]*apriori[i,]+(1-alpha[i])*Emp[i,]
R+   }
R+   return(out)
R+ }
\end{CodeInput}
\end{CodeChunk}

We then apply it to the weather example:

\begin{CodeChunk}

\begin{CodeInput}
R> trueMc<-as(matrix(c(0.1, .9,.7,.3),nrow = 2, byrow = 2),"markovchain")
R> aprioriMc<-as(matrix(c(0.5, .5,.5,.5),nrow = 2, byrow = 2),"markovchain")
R> 
R> smallSample<-rmarkovchain(n=20,object = trueMc)
R> smallSampleRawTransitions<-createSequenceMatrix(stringchar = smallSample)
R> pseudoBayesEstimator(
R+   raw = smallSampleRawTransitions, 
R+   apriori = aprioriMc@transitionMatrix
R+ ) - trueMc@transitionMatrix
\end{CodeInput}

\begin{CodeOutput}
            s1          s2
s1 -0.10000000  0.10000000
s2  0.05471698 -0.05471698
\end{CodeOutput}

\begin{CodeInput}
R> biggerSample<-rmarkovchain(n=100,object = trueMc)
R> biggerSampleRawTransitions<-createSequenceMatrix(stringchar = biggerSample)
R> pseudoBayesEstimator(
R+   raw = biggerSampleRawTransitions,
R+   apriori = aprioriMc@transitionMatrix
R+ ) - trueMc@transitionMatrix
\end{CodeInput}

\begin{CodeOutput}
             s1           s2
s1  0.043578141 -0.043578141
s2 -0.007429331  0.007429331
\end{CodeOutput}

\begin{CodeInput}
R> bigSample<-rmarkovchain(n=1000,object = trueMc)
R> bigSampleRawTransitions<-createSequenceMatrix(stringchar = bigSample)
R> pseudoBayesEstimator(
R+   raw = bigSampleRawTransitions,
R+   apriori = aprioriMc@transitionMatrix
R+ ) - trueMc@transitionMatrix
\end{CodeInput}

\begin{CodeOutput}
            s1         s2
s1 -0.02668658 0.02668658
s2 -0.01557906 0.01557906
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{bayesian-estimation}{%
\subsection{Bayesian Estimation}\label{bayesian-estimation}}

The \pkg{markovchain} package provides functionality for maximum a posteriori (MAP) estimation of the chain parameters (at the time of writing this document, only first order models are supported) by Bayesian inference. It also computes the probability of observing a new data set, given a (different) data set. This vignette provides the mathematical description for the methods employed by the package.

\hypertarget{notation-and-set-up}{%
\subsubsection{Notation and set-up}\label{notation-and-set-up}}

The data is denoted by \(D\), the model parameters (transition matrix) by \(\theta\). The object of interest is \(P(\theta | D)\) (posterior density). \(\mathcal{A}\) represents an alphabet class, each of whose members represent a state of the chain. Therefore

\[D = s_0 s_1 ... s_{N-1}, s_t \in \mathcal{A}\]

where \(N\) is the length of the data set. Also,

\[\theta = \{p(s|u), s \in \mathcal{A}, u \in \mathcal{A}  \}\]
where \(\sum_{s \in \mathcal{A}} p(s|u) = 1\) for each \(u \in \mathcal{A}\).

Our objective is to find \(\theta\) which maximises the posterior. That is, if our solution is denoted by \(\hat{\theta}\), then

\[\hat{\theta} = \underset{\theta}{argmax}P(\theta | D)\]

where the search space is the set of right stochastic matrices of dimension \(|\mathcal{A}|x|\mathcal{A}|\).

\(n(u, s)\) denotes the number of times the word \(us\) occurs in \(D\) and \(n(u)=\sum_{s \in \mathcal{A}}n(u, s)\). The hyperparameters are similarly denoted by \(\alpha(u, s)\) and \(\alpha(u)\) respectively.

\hypertarget{methods}{%
\subsubsection{Methods}\label{methods}}

Given \(D\), its likelihood conditioned on the observed initial state in D is given by
\[P(D|\theta) = \prod_{s \in \mathcal{A}} \prod_{u \in \mathcal{A}} p(s|u)^{n(u, s)}\]

Conjugate priors are used to model the prior \(P(\theta)\). The reasons are two fold:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Exact expressions can be derived for the MAP estimates, expectations and even variances
\item
  Model order selection/comparison can be implemented easily (available in a future release of the package)
\end{enumerate}

The hyperparameters determine the form of the prior distribution, which is a product of Dirichlet distributions

\[P(\theta) = \prod_{u \in \mathcal{A}} \Big\{ \frac{\Gamma(\alpha(u))}{\prod_{s \in \mathcal{A}} \Gamma(\alpha(u, s))} \prod_{s \in \mathcal{A}} p(s|u)^{\alpha(u, s)) - 1} \Big\}\]

where \(\Gamma(.)\) is the Gamma function. The hyperparameters are specified using the \texttt{hyperparam} argument in the \texttt{markovchainFit} function. If this argument is not specified, then a default value of 1 is assigned to each hyperparameter resulting in the prior distribution of each chain parameter to be uniform over \([0,1]\).

Given the likelihood and the prior as described above, the evidence \(P(D)\) is simply given by

\[P(D) = \int P(D|\theta) P(\theta) d\theta\]

which simplifies to

\[
P(D) = \prod_{u \in \mathcal{A}} \Big\{ \frac{\Gamma(\alpha(u))}{\prod_{s \in \mathcal{A}} \Gamma(\alpha(u, s))} \frac{\prod_{s \in \mathcal{A}} \Gamma(n(u, s) + \alpha(u, s))}{\Gamma(\alpha(u) + n(u))} \Big\}
\]

Using Bayes' theorem, the posterior now becomes (thanks to the choice of conjugate priors)
\[
P(\theta | D) = \prod_{u \in \mathcal{A}} \Big\{ \frac{\Gamma(n(u) + \alpha(u))}{\prod_{s \in \mathcal{A}} \Gamma(n(u, s) + \alpha(u, s))} \prod_{s \in \mathcal{A}} p(s|u)^{n(u, s) + \alpha(u, s)) - 1} \Big\}
\]

Since this is again a product of Dirichlet distributions, the marginalised distribution of a particular parameter \(P(s|u)\) of our chain is given by
\[
P(s|u) \sim Beta(n(u, s) + \alpha(u, s), n(u) + \alpha(u) - n(u, s) - \alpha(u, s))
\]

Thus, the MAP estimate \(\hat{\theta}\) is given by
\[
\hat{\theta} = \Big\{ \frac{n(u, s) + \alpha(u, s) - 1}{n(u) + \alpha(u) - |\mathcal{A}|}, s \in \mathcal{A}, u \in \mathcal{A} \Big\}
\]

The function also returns the expected value, given by
\[
\text{E}_{\text{post}} p(s|u) = \Big\{ \frac{n(u, s) + \alpha(u, s)}{n(u) + \alpha(u)}, s \in \mathcal{A}, u \in \mathcal{A} \Big\}
\]

The variance is given by
\[
\text{Var}_{\text{post}} p(s|u) = \frac{n(u, s) + \alpha(u, s)}{(n(u) + \alpha(u))^2} \frac{n(u) + \alpha(u) - n(u, s) - \alpha(u, s)}{n(u) + \alpha(u) + 1}
\]

The square root of this quantity is the standard error, which is returned by the function.

The confidence intervals are constructed by computing the inverse of the beta integral.

\hypertarget{predictive-distribution}{%
\subsubsection{Predictive distribution}\label{predictive-distribution}}

Given the old data set, the probability of observing new data is \(P(D'|D)\) where \(D'\) is the new data set. Let \(m(u, s), m(u)\) denote the corresponding counts for the new data. Then,
\[
P(D'|D) = \int P(D' | \theta) P(\theta | D) d\theta
\]
We already know the expressions for both quantities in the integral and it turns out to be similar to evaluating the evidence
\[
P(D'|D) = \prod_{u \in \mathcal{A}} \Big\{ \frac{\Gamma(\alpha(u))}{\prod_{s \in \mathcal{A}} \Gamma(\alpha(u, s))} \frac{\prod_{s \in \mathcal{A}} \Gamma(n(u, s) + m(u, s) + \alpha(u, s))}{\Gamma(\alpha(u) + n(u) + m(u))} \Big\}
\]

\hypertarget{choosing-the-hyperparameters}{%
\subsubsection{Choosing the hyperparameters}\label{choosing-the-hyperparameters}}

The hyperparameters model the shape of the parameters' prior distribution. These must be provided by the user. The package offers functionality to translate a given prior belief transition matrix into the hyperparameter matrix. It is assumed that this belief matrix corresponds to the mean value of the parameters. Since the relation
\[
\text{E}_{\text{prior}} p(s | u) = \frac{\alpha(u, s)}{\alpha(u)}
\]

holds, the function accepts as input the belief matrix as well as a scaling vector (serves as a proxy for \(\alpha(.)\)) and proceeds to compute \(\alpha(., .)\).

Alternatively, the function accepts a data sample and infers the hyperparameters from it. Since the mode of a parameter (with respect to the prior distribution) is proportional to one less than the corresponding hyperparameter, we set

\[
\alpha(u, s) - 1 = m(u, s)
\]

where \(m(u, s)\) is the \(u\rightarrow s\) transition count in the data sample. This is regarded as a `fake count' which helps \(\alpha(u, s)\) to reflect knowledge of the data sample.

\hypertarget{usage-and-examples}{%
\subsubsection{Usage and examples}\label{usage-and-examples}}

\begin{CodeChunk}

\begin{CodeInput}
R> weatherStates <- c("sunny", "cloudy", "rain")
R> byRow <- TRUE
R> weatherMatrix <- matrix(data = c(0.7, 0.2, 0.1, 
R+                                  0.3, 0.4, 0.3, 
R+                                  0.2, 0.4, 0.4), 
R+                         byrow = byRow, nrow = 3, 
R+                         dimnames = list(weatherStates, weatherStates))
R> mcWeather <- new("markovchain", states = weatherStates, 
R+                  byrow = byRow, transitionMatrix = weatherMatrix, 
R+                  name = "Weather")      
R> weathersOfDays <- rmarkovchain(n = 365, object = mcWeather, t0 = "sunny")
\end{CodeInput}
\end{CodeChunk}

For the purpose of this section, we shall continue to use the weather of days example introduced in the main vignette of the package (reproduced above for convenience).

Let us invoke the fit function to estimate the MAP parameters with 92\% confidence bounds and hyperparameters as shown below, based on the first 200 days of the weather data. Additionally, let us find out what the probability is of observing the weather data for the next 165 days. The usage would be as follows

\begin{CodeChunk}

\begin{CodeInput}
R> hyperMatrix<-matrix(c(1, 1, 2, 
R+                       3, 2, 1,
R+                       2, 2, 3), 
R+                     nrow = 3, byrow = TRUE,
R+                     dimnames = list(weatherStates,weatherStates))
R> markovchainFit(weathersOfDays[1:200], method = "map", 
R+                confidencelevel = 0.92, hyperparam = hyperMatrix)
\end{CodeInput}

\begin{CodeOutput}
$estimate
Bayesian Fit 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 cloudy, rain, sunny 
 The transition matrix  (by rows)  is defined as follows: 
          cloudy      rain     sunny
cloudy 0.4687500 0.2343750 0.2968750
rain   0.3061224 0.4489796 0.2448980
sunny  0.1914894 0.1170213 0.6914894


$expectedValue
          cloudy      rain     sunny
cloudy 0.4626866 0.2388060 0.2985075
rain   0.3076923 0.4423077 0.2500000
sunny  0.1958763 0.1237113 0.6804124

$standardError
           [,1]       [,2]       [,3]
[1,] 0.06046483 0.05170301 0.05549255
[2,] 0.06339718 0.06822156 0.05947887
[3,] 0.04009030 0.03325947 0.04710511

$confidenceInterval
$confidenceInterval$confidenceLevel
[1] 0.92

$confidenceInterval$lowerEndpointMatrix
          [,1]      [,2]      [,3]
[1,] 0.3777832 0.1460639 0.2071324
[2,] 0.2053598 0.3467425 0.1451200
[3,] 0.1187764 0.0000000 0.6128912

$confidenceInterval$upperEndpointMatrix
          [,1]      [,2]      [,3]
[1,] 1.0000000 0.3259590 0.4016554
[2,] 0.4284971 1.0000000 0.3515457
[3,] 0.2600255 0.1727529 1.0000000


$logLikelihood
[1] -187.6309
\end{CodeOutput}

\begin{CodeInput}
R> predictiveDistribution(weathersOfDays[1:200], 
R+                        weathersOfDays[201:365],hyperparam = hyperMatrix) 
\end{CodeInput}

\begin{CodeOutput}
[1] -148.5388
\end{CodeOutput}
\end{CodeChunk}

The results should not change after permuting the dimensions of the matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> hyperMatrix2<- hyperMatrix[c(2,3,1), c(2,3,1)]
R> markovchainFit(weathersOfDays[1:200], method = "map", 
R+                confidencelevel = 0.92, hyperparam = hyperMatrix2)
\end{CodeInput}

\begin{CodeOutput}
$estimate
Bayesian Fit 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 cloudy, rain, sunny 
 The transition matrix  (by rows)  is defined as follows: 
          cloudy      rain     sunny
cloudy 0.4687500 0.2343750 0.2968750
rain   0.3061224 0.4489796 0.2448980
sunny  0.1914894 0.1170213 0.6914894


$expectedValue
          cloudy      rain     sunny
cloudy 0.4626866 0.2388060 0.2985075
rain   0.3076923 0.4423077 0.2500000
sunny  0.1958763 0.1237113 0.6804124

$standardError
           [,1]       [,2]       [,3]
[1,] 0.06046483 0.05170301 0.05549255
[2,] 0.06339718 0.06822156 0.05947887
[3,] 0.04009030 0.03325947 0.04710511

$confidenceInterval
$confidenceInterval$confidenceLevel
[1] 0.92

$confidenceInterval$lowerEndpointMatrix
          [,1]      [,2]      [,3]
[1,] 0.3777832 0.1460639 0.2071324
[2,] 0.2053598 0.3467425 0.1451200
[3,] 0.1187764 0.0000000 0.6128912

$confidenceInterval$upperEndpointMatrix
          [,1]      [,2]      [,3]
[1,] 1.0000000 0.3259590 0.4016554
[2,] 0.4284971 1.0000000 0.3515457
[3,] 0.2600255 0.1727529 1.0000000


$logLikelihood
[1] -187.6309
\end{CodeOutput}

\begin{CodeInput}
R> predictiveDistribution(weathersOfDays[1:200], 
R+                        weathersOfDays[201:365],hyperparam = hyperMatrix2)
\end{CodeInput}

\begin{CodeOutput}
[1] -148.5388
\end{CodeOutput}
\end{CodeChunk}

Note that the predictive probability is very small. However, this can be useful when comparing model orders.
Suppose we have an idea of the (prior) transition matrix corresponding to the expected value of the parameters, and have a data set from which we want to deduce the MAP estimates. We can infer the hyperparameters from this known transition matrix itself, and use this to obtain our MAP estimates.

\begin{CodeChunk}

\begin{CodeInput}
R> inferHyperparam(transMatr = weatherMatrix, scale = c(10, 10, 10))
\end{CodeInput}

\begin{CodeOutput}
$scaledInference
       cloudy rain sunny
cloudy      4    3     3
rain        4    4     2
sunny       2    1     7
\end{CodeOutput}
\end{CodeChunk}

Alternatively, we can use a data sample to infer the hyperparameters.

\begin{CodeChunk}

\begin{CodeInput}
R> inferHyperparam(data = weathersOfDays[1:15])
\end{CodeInput}

\begin{CodeOutput}
$dataInference
       cloudy rain sunny
cloudy      1    1     2
rain        2    3     1
sunny       1    2    10
\end{CodeOutput}
\end{CodeChunk}

In order to use the inferred hyperparameter matrices, we do

\begin{CodeChunk}

\begin{CodeInput}
R> hyperMatrix3 <- inferHyperparam(transMatr = weatherMatrix, 
R+                                 scale = c(10, 10, 10))
R> hyperMatrix3 <- hyperMatrix3$scaledInference
R> hyperMatrix4 <- inferHyperparam(data = weathersOfDays[1:15])
R> hyperMatrix4 <- hyperMatrix4$dataInference
\end{CodeInput}
\end{CodeChunk}

Now we can safely use \texttt{hyperMatrix3} and \texttt{hyperMatrix4} with \texttt{markovchainFit} (in the \texttt{hyperparam} argument).

Supposing we don't provide any hyperparameters, then the prior is uniform. This is the same as maximum likelihood.

\begin{CodeChunk}

\begin{CodeInput}
R> data(preproglucacon)
R> preproglucacon <- preproglucacon[[2]]
R> MLEest <- markovchainFit(preproglucacon, method = "mle")
R> MAPest <- markovchainFit(preproglucacon, method = "map")
R> MLEest$estimate
\end{CodeInput}

\begin{CodeOutput}
MLE Fit 
 A  4 - dimensional discrete Markov Chain defined by the following states: 
 A, C, G, T 
 The transition matrix  (by rows)  is defined as follows: 
          A         C          G         T
A 0.3585271 0.1434109 0.16666667 0.3313953
C 0.3840304 0.1558935 0.02281369 0.4372624
G 0.3053097 0.1991150 0.15044248 0.3451327
T 0.2844523 0.1819788 0.17667845 0.3568905
\end{CodeOutput}

\begin{CodeInput}
R> MAPest$estimate
\end{CodeInput}

\begin{CodeOutput}
Bayesian Fit 
 A  4 - dimensional discrete Markov Chain defined by the following states: 
 A, C, G, T 
 The transition matrix  (by rows)  is defined as follows: 
          A         C          G         T
A 0.3585271 0.1434109 0.16666667 0.3313953
C 0.3840304 0.1558935 0.02281369 0.4372624
G 0.3053097 0.1991150 0.15044248 0.3451327
T 0.2844523 0.1819788 0.17667845 0.3568905
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{sec:applications}{%
\section{Applications}\label{sec:applications}}

This section shows applications of DTMC in various fields.

\hypertarget{app:weather}{%
\subsection{Weather forecasting}\label{app:weather}}

Markov chains provide a simple model to predict the next day's weather given the current meteorological condition. The first application herewith shown is the ``Land of Oz example'' from \cite{landOfOz}, the second is the ``Alofi Island Rainfall'' from \cite{averyHenderson}.

\hypertarget{sec:wfLandOfOz}{%
\subsubsection{Land of Oz}\label{sec:wfLandOfOz}}

The Land of Oz is
acknowledged not to have ideal weather conditions at all:
the weather is snowy or rainy very often and, once more, there are never two
nice days in a row. Consider three weather states: rainy, nice and snowy. Let the transition matrix be as in the following:

\begin{CodeChunk}

\begin{CodeInput}
R> mcWP <- new("markovchain", states = c("rainy", "nice", "snowy"),
R+          transitionMatrix = matrix(c(0.5, 0.25, 0.25,
R+                                    0.5, 0, 0.5,
R+                                    0.25,0.25,0.5), byrow = T, nrow = 3))
\end{CodeInput}
\end{CodeChunk}

Given that today it is a nice day, the corresponding stochastic row vector is
\(w_{0}=(0\:,1\:,0)\) and the forecast after 1, 2 and 3 days are given by

\begin{CodeChunk}

\begin{CodeInput}
R> W0 <- t(as.matrix(c(0, 1, 0)))
R> W1 <- W0 * mcWP; W1
\end{CodeInput}

\begin{CodeOutput}
     rainy nice snowy
[1,]   0.5    0   0.5
\end{CodeOutput}

\begin{CodeInput}
R> W2 <- W0 * (mcWP ^ 2); W2
\end{CodeInput}

\begin{CodeOutput}
     rainy nice snowy
[1,] 0.375 0.25 0.375
\end{CodeOutput}

\begin{CodeInput}
R> W3 <- W0 * (mcWP ^ 3); W3
\end{CodeInput}

\begin{CodeOutput}
       rainy   nice   snowy
[1,] 0.40625 0.1875 0.40625
\end{CodeOutput}
\end{CodeChunk}

As can be seen from \(w_{1}\), if in the Land of Oz today is a nice day, tomorrow it will rain or snow with probability 1. One week later, the prediction can be computed as

\begin{CodeChunk}

\begin{CodeInput}
R> W7 <- W0 * (mcWP ^ 7)
R> W7
\end{CodeInput}

\begin{CodeOutput}
         rainy      nice     snowy
[1,] 0.4000244 0.1999512 0.4000244
\end{CodeOutput}
\end{CodeChunk}

The steady state of the chain can be computed by means of the \texttt{steadyStates} method.

\begin{CodeChunk}

\begin{CodeInput}
R> q <- steadyStates(mcWP)
R> q
\end{CodeInput}

\begin{CodeOutput}
     rainy nice snowy
[1,]   0.4  0.2   0.4
\end{CodeOutput}
\end{CodeChunk}

Note that, from the seventh day on, the predicted probabilities are substantially equal to the steady state of the chain and they don't depend from the starting point, as the following code shows.

\begin{CodeChunk}

\begin{CodeInput}
R> R0 <- t(as.matrix(c(1, 0, 0)))
R> R7 <- R0 * (mcWP ^ 7); R7
\end{CodeInput}

\begin{CodeOutput}
         rainy      nice     snowy
[1,] 0.4000244 0.2000122 0.3999634
\end{CodeOutput}

\begin{CodeInput}
R> S0 <- t(as.matrix(c(0, 0, 1)))
R> S7 <- S0 * (mcWP ^ 7); S7
\end{CodeInput}

\begin{CodeOutput}
         rainy      nice     snowy
[1,] 0.3999634 0.2000122 0.4000244
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{sec:wfAlofi}{%
\subsubsection{Alofi Island Rainfall}\label{sec:wfAlofi}}

Alofi Island daily rainfall
data were recorded from January 1st, 1987 until December 31st, 1989 and
classified into three states: ``0'' (no rain), ``1-5'' (from non zero until 5 mm) and ``6+'' (more than 5mm). The corresponding dataset is provided within the \pkg{markovchain} package.

\begin{CodeChunk}

\begin{CodeInput}
R> data("rain", package = "markovchain")
R> table(rain$rain)
\end{CodeInput}

\begin{CodeOutput}

  0 1-5  6+ 
548 295 253 
\end{CodeOutput}
\end{CodeChunk}

The underlying transition matrix is estimated as follows.

\begin{CodeChunk}

\begin{CodeInput}
R> mcAlofi <- markovchainFit(data = rain$rain, name = "Alofi MC")$estimate
R> mcAlofi
\end{CodeInput}

\begin{CodeOutput}
Alofi MC 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 0, 1-5, 6+ 
 The transition matrix  (by rows)  is defined as follows: 
            0       1-5        6+
0   0.6605839 0.2299270 0.1094891
1-5 0.4625850 0.3061224 0.2312925
6+  0.1976285 0.3122530 0.4901186
\end{CodeOutput}
\end{CodeChunk}

The long term daily rainfall distribution is obtained by means of the \texttt{steadyStates} method.

\begin{CodeChunk}

\begin{CodeInput}
R> steadyStates(mcAlofi)
\end{CodeInput}

\begin{CodeOutput}
             0       1-5        6+
[1,] 0.5008871 0.2693656 0.2297473
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{app:fin}{%
\subsection{Finance and Economics}\label{app:fin}}

Other relevant applications of DTMC can be found in Finance and Economics.

\hypertarget{fin:fin}{%
\subsubsection{Finance}\label{fin:fin}}

Credit ratings transitions have been successfully modelled with discrete time Markov chains. Some rating agencies publish transition matrices that show the empirical transition probabilities across credit ratings. The example that follows
comes from \pkg{CreditMetrics} \proglang{R} package \citep{CreditMetricsR},
carrying Standard \& Poor's published data.

\begin{CodeChunk}

\begin{CodeInput}
R> rc <- c("AAA", "AA", "A", "BBB", "BB", "B", "CCC", "D")
R> creditMatrix <- matrix(
R+   c(90.81, 8.33, 0.68, 0.06, 0.08, 0.02, 0.01, 0.01,
R+     0.70, 90.65, 7.79, 0.64, 0.06, 0.13, 0.02, 0.01,
R+     0.09, 2.27, 91.05, 5.52, 0.74, 0.26, 0.01, 0.06,
R+     0.02, 0.33, 5.95, 85.93, 5.30, 1.17, 1.12, 0.18,
R+     0.03, 0.14, 0.67, 7.73, 80.53, 8.84, 1.00, 1.06,
R+     0.01, 0.11, 0.24, 0.43, 6.48, 83.46, 4.07, 5.20,
R+     0.21, 0, 0.22, 1.30, 2.38, 11.24, 64.86, 19.79,
R+     0, 0, 0, 0, 0, 0, 0, 100
R+    )/100, 8, 8, dimnames = list(rc, rc), byrow = TRUE)
\end{CodeInput}
\end{CodeChunk}

It is easy to convert such matrices into \texttt{markovchain} objects and to perform some analyses

\begin{CodeChunk}

\begin{CodeInput}
R> creditMc <- new("markovchain", transitionMatrix = creditMatrix, 
R+                 name = "S&P Matrix")
R> absorbingStates(creditMc)
\end{CodeInput}

\begin{CodeOutput}
[1] "D"
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{fin:ec}{%
\subsubsection{Economics}\label{fin:ec}}

For a recent application of \pkg{markovchain} in Economic, see \cite{manchesterR}.

A dynamic system generates two kinds of economic effects \citep{bardPpt}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  those incurred when the system is in a specified state, and
\item
  those incurred when the system makes a transition from one state to another.
\end{enumerate}

Let the monetary amount of being in a particular state be represented as a m-dimensional column vector \(c^{\rm{S}}\), while let the monetary amount of a transition be embodied in a \(C^{R}\) matrix in which each component specifies the monetary amount of going from state i to state j in a single step. Henceforth, Equation \eqref{eq:cost} represents the monetary of being in state \(i\).

\begin{equation}
{c_i} = c_i^{\rm{S}} + \sum\limits_{j = 1}^m {C_{ij}^{\rm{R}}} {p_{ij}}.
\label{eq:cost}
\end{equation}

Let \(\bar c = \left[ c_i \right]\) and let \(e_i\) be the vector valued 1 in the initial state and 0 in all other, then, if \(f_n\) is the random variable representing the economic return associated with the stochastic process at time \(n\), Equation \eqref{eq:return} holds:

\begin{equation}
E\left[ {{f_n}\left( {{X_n}} \right)|{X_0} = i} \right] = {e_i}{P^n}\bar c.
\label{eq:return}
\end{equation}

The following example assumes that a telephone company models the transition probabilities between customer/non-customer status by matrix \(P\) and the cost associated to states by matrix \(M\).

\begin{CodeChunk}

\begin{CodeInput}
R> statesNames <- c("customer", "non customer")
R> P <- zeros(2); P[1, 1] <- .9; P[1, 2] <- .1; P[2, 2] <- .95; P[2, 1] <- .05;
R> rownames(P) <- statesNames; colnames(P) <- statesNames
R> mcP <- new("markovchain", transitionMatrix = P, name = "Telephone company")
R> M <- zeros(2); M[1, 1] <- -20; M[1, 2] <- -30; M[2, 1] <- -40; M[2, 2] <- 0
\end{CodeInput}
\end{CodeChunk}

If the average revenue for existing customer is +100, the cost per state is computed as follows.

\begin{CodeChunk}

\begin{CodeInput}
R> c1 <- 100 + conditionalDistribution(mcP, state = "customer") %*% M[1,]
R> c2 <- 0 + conditionalDistribution(mcP, state = "non customer") %*% M[2,]
\end{CodeInput}
\end{CodeChunk}

For an existing customer, the expected gain (loss) at the fifth year is given by the following code.

\begin{CodeChunk}

\begin{CodeInput}
R> as.numeric((c(1, 0)* mcP ^ 5) %*% (as.vector(c(c1, c2))))
\end{CodeInput}

\begin{CodeOutput}
[1] 48.96009
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{app:act}{%
\subsection{Actuarial science}\label{app:act}}

Markov chains are widely applied in the field of actuarial science. Two
classical applications are policyholders' distribution across Bonus Malus
classes in Motor Third Party Liability (MTPL) insurance (Section \ref{sec:bm}) and health insurance pricing and reserving
(Section \ref{sec:hi}).

\hypertarget{sec:bm}{%
\subsubsection{MPTL Bonus Malus}\label{sec:bm}}

Bonus Malus (BM) contracts grant the policyholder a discount (enworsen) as a function of the number of claims in the experience period. The discount (enworsen) is applied on a premium that already allows for known (a priori) policyholder characteristics \citep{denuit2007actuarial} and it usually depends on vehicle, territory, the demographic profile of the policyholder, and policy coverages deep (deductible and policy limits).\textbackslash{}
Since the proposed BM level depends on the claim on the previous period, it can be modelled by a discrete Markov chain. A very simplified example follows. Assume a BM scale from 1 to 5, where 4 is the starting level. The evolution rules are shown in Equation \ref{eq:BM}:

\begin{equation}
bm_{t + 1} = \max \left( {1,bm_{t} - 1} \right)*\left( {\tilde N = 0} \right) + \min \left( {5,bm_{t} + 2*\tilde N} \right)*\left( {\tilde N \ge 1} \right).
\label{eq:BM}
\end{equation}

The number of claim \(\tilde N\) is a random variable that is assumed
to be Poisson distributed.

\begin{CodeChunk}

\begin{CodeInput}
R> getBonusMalusMarkovChain <- function(lambda) {
R+  bmMatr <- zeros(5)
R+  bmMatr[1, 1] <- dpois(x = 0, lambda)
R+  bmMatr[1, 3] <- dpois(x = 1, lambda)
R+  bmMatr[1, 5] <- 1 - ppois(q = 1, lambda)
R+  
R+  bmMatr[2, 1] <- dpois(x = 0, lambda)
R+  bmMatr[2, 4] <- dpois(x = 1, lambda)
R+  bmMatr[2, 5] <- 1 - ppois(q = 1, lambda)
R+  
R+  bmMatr[3, 2] <- dpois(x = 0, lambda)
R+  bmMatr[3, 5] <- 1 - dpois(x=0, lambda)
R+  
R+  bmMatr[4, 3] <- dpois(x = 0, lambda)
R+  bmMatr[4, 5] <- 1 - dpois(x = 0, lambda)
R+   
R+  bmMatr[5, 4] <- dpois(x = 0, lambda)
R+  bmMatr[5, 5] <- 1 - dpois(x = 0, lambda)
R+  stateNames <- as.character(1:5)
R+  out <- new("markovchain", transitionMatrix = bmMatr, 
R+              states = stateNames, name = "BM Matrix")
R+  return(out)
R+ }
\end{CodeInput}
\end{CodeChunk}

Assuming that the a-priori claim frequency per car-year is 0.05 in the class (being the class the group of policyholders that share the same common characteristics), the underlying BM transition matrix and its underlying steady state are as follows.

\begin{CodeChunk}

\begin{CodeInput}
R> bmMc <- getBonusMalusMarkovChain(0.05)
R> as.numeric(steadyStates(bmMc))
\end{CodeInput}

\begin{CodeOutput}
[1] 0.895836079 0.045930498 0.048285405 0.005969247 0.003978772
\end{CodeOutput}
\end{CodeChunk}

If the underlying BM coefficients of the class are 0.5, 0.7, 0.9, 1.0, 1.25, this means that the average BM coefficient applied on the long run to the class is given by

\begin{CodeChunk}

\begin{CodeInput}
R> sum(as.numeric(steadyStates(bmMc)) * c(0.5, 0.7, 0.9, 1, 1.25))
\end{CodeInput}

\begin{CodeOutput}
[1] 0.534469
\end{CodeOutput}
\end{CodeChunk}

This means that the average premium paid by policyholders in the portfolio almost halves in the long run.

\hypertarget{sec:hi}{%
\subsubsection{Health insurance example}\label{sec:hi}}

Actuaries quantify the risk inherent in insurance contracts evaluating the premium of insurance contract to be sold (therefore covering future risk) and evaluating the actuarial reserves of existing portfolios (the liabilities in terms of benefits or claims payments due to policyholder arising from previously sold contracts), see \cite{deshmukh2012multiple} for details.

An applied example can be performed using the data from \cite{de2016assicurazioni} that has been saved in the \texttt{exdata} folder.

\begin{CodeChunk}

\begin{CodeInput}
R> ltcDemoPath<-system.file("extdata", "ltdItaData.txt", 
R+                          package = "markovchain")
R> ltcDemo<-read.table(file = ltcDemoPath, header=TRUE, 
R+                     sep = ";", dec = ".")
R> head(ltcDemo)
\end{CodeInput}

\begin{CodeOutput}
  age          pAD        pID          pAI       pAA
1  20 0.0004616002 0.01083364 0.0001762467 0.9993622
2  21 0.0004824888 0.01079719 0.0001710577 0.9993465
3  22 0.0004949938 0.01177076 0.0001592333 0.9993458
4  23 0.0005042935 0.01159394 0.0001605731 0.9993351
5  24 0.0005074193 0.01260574 0.0001606504 0.9993319
6  25 0.0005154267 0.01526364 0.0001643603 0.9993202
\end{CodeOutput}
\end{CodeChunk}

The data shows the probability of transition between the state of (A)ctive, to (I)ll and Dead. It is easy to complete the
transition matrix.

\begin{CodeChunk}

\begin{CodeInput}
R> ltcDemo<-transform(ltcDemo,
R+                    pIA=0,
R+                    pII=1-pID,
R+                    pDD=1,
R+                    pDA=0,
R+                    pDI=0)
\end{CodeInput}
\end{CodeChunk}

Now we build a function that returns the transition during the \(t+1\) th year, assuming that the subject has attained year \(t\).

\begin{CodeChunk}

\begin{CodeInput}
R> possibleStates<-c("A","I","D")
R> getMc4Age<-function(age) {
R+   transitionsAtAge<-ltcDemo[ltcDemo$age==age,]
R+   
R+   myTransMatr<-matrix(0, nrow=3,ncol = 3,
R+                       dimnames = list(possibleStates, possibleStates))
R+   myTransMatr[1,1]<-transitionsAtAge$pAA[1]
R+   myTransMatr[1,2]<-transitionsAtAge$pAI[1]
R+   myTransMatr[1,3]<-transitionsAtAge$pAD[1]
R+   myTransMatr[2,2]<-transitionsAtAge$pII[1]
R+   myTransMatr[2,3]<-transitionsAtAge$pID[1]
R+   myTransMatr[3,3]<-1
R+   
R+   myMc<-new("markovchain", transitionMatrix = myTransMatr,
R+             states = possibleStates,
R+             name = paste("Age",age,"transition matrix"))
R+   
R+   return(myMc)
R+ 
R+ }
\end{CodeInput}
\end{CodeChunk}

Cause transitions are not homogeneous across ages, we use a \texttt{markovchainList} object to describe the transition probabilities for a guy starting at age 100.

\begin{CodeChunk}

\begin{CodeInput}
R> getFullTransitionTable<-function(age){
R+   ageSequence<-seq(from=age, to=120)
R+   k=1
R+   myList=list()
R+   for ( i in ageSequence) {
R+     mc_age_i<-getMc4Age(age = i)
R+     myList[[k]]<-mc_age_i
R+     k=k+1
R+   }
R+   myMarkovChainList<-new("markovchainList", markovchains = myList,
R+                          name = paste("TransitionsSinceAge", age, sep = ""))
R+   return(myMarkovChainList)
R+ }
R> transitionsSince100<-getFullTransitionTable(age=100)
\end{CodeInput}
\end{CodeChunk}

We can use such transition for simulating ten life trajectories for a guy that begins ``active'' (A) aged 100:

\begin{CodeChunk}

\begin{CodeInput}
R> rmarkovchain(n = 10, object = transitionsSince100,
R+              what = "matrix", t0 = "A", include.t0 = TRUE)
\end{CodeInput}

\begin{CodeOutput}
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
 [1,] "A"  "A"  "I"  "I"  "I"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [2,] "A"  "A"  "I"  "D"  "D"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [3,] "A"  "I"  "D"  "D"  "D"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [4,] "A"  "D"  "D"  "D"  "D"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [5,] "A"  "A"  "A"  "A"  "A"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [6,] "A"  "A"  "A"  "A"  "A"  "A"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [7,] "A"  "A"  "A"  "D"  "D"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
 [8,] "A"  "A"  "A"  "A"  "A"  "A"  "A"  "A"  "A"  "A"   "D"   "D"   "D"  
 [9,] "A"  "A"  "D"  "D"  "D"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
[10,] "A"  "I"  "I"  "D"  "D"  "D"  "D"  "D"  "D"  "D"   "D"   "D"   "D"  
      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]
 [1,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [2,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [3,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [4,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [5,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [6,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [7,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [8,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
 [9,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
[10,] "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"   "D"  
\end{CodeOutput}
\end{CodeChunk}

Lets consider 1000 simulated live trajectories, for a healty guy aged 80. We can compute the expected time a guy will be disabled starting active at age 80.

\begin{CodeChunk}

\begin{CodeInput}
R> transitionsSince80<-getFullTransitionTable(age=80)
R> lifeTrajectories<-rmarkovchain(n=1e3, object=transitionsSince80,
R+                                what="matrix",t0="A",include.t0=TRUE)
R> temp<-matrix(0,nrow=nrow(lifeTrajectories),ncol = ncol(lifeTrajectories))
R> temp[lifeTrajectories=="I"]<-1
R> expected_period_disabled<-mean(rowSums((temp)))
R> expected_period_disabled
\end{CodeInput}

\begin{CodeOutput}
[1] 1.24
\end{CodeOutput}
\end{CodeChunk}

Assuming that the health insurance will pay a benefit of 12000 per year disabled and that the real interest rate is 0.02, we can compute the lump sum premium at 80.

\begin{CodeChunk}

\begin{CodeInput}
R> mean(rowMeans(12000*temp%*%( matrix((1+0.02)^-seq(from=0, to=ncol(temp)-1)))))
\end{CodeInput}

\begin{CodeOutput}
[1] 12399.44
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{app:sociology}{%
\subsection{Sociology}\label{app:sociology}}

Markov chains have been actively used to model progressions and regressions between social classes. The first study was performed by \cite{glassHall}, while a more recent application can be found in \cite{blandenEtAlii}. The table that follows shows the income quartile of the father when the son was 16 (in 1984) and the income quartile of the son when aged 30 (in 2000) for the 1970 cohort.

\begin{CodeChunk}

\begin{CodeInput}
R> data("blanden")
R> mobilityMc <- as(blanden, "markovchain")
R> mobilityMc
\end{CodeInput}

\begin{CodeOutput}
Unnamed Markov chain 
 A  4 - dimensional discrete Markov Chain defined by the following states: 
 Bottom, 2nd, 3rd, Top 
 The transition matrix  (by rows)  is defined as follows: 
             2nd       3rd    Bottom       Top
Bottom 0.2900000 0.2200000 0.3800000 0.1100000
2nd    0.2772277 0.2574257 0.2475248 0.2178218
3rd    0.2626263 0.2828283 0.2121212 0.2424242
Top    0.1700000 0.2500000 0.1600000 0.4200000
\end{CodeOutput}
\end{CodeChunk}

The underlying transition graph is plotted in Figure \ref{fig:mobility}.

\begin{CodeChunk}
\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{/tmp/RtmpghR4s0/file36246af82052/articles/an_introduction_to_markovchain_package_files/figure-latex/mobility-1} 

}

\caption[1970 UK cohort mobility data]{1970 UK cohort mobility data.}\label{fig:mobility}
\end{figure}
\end{CodeChunk}

The steady state distribution is computed as follows. Since transition across quartiles are shown, the probability function is evenly 0.25.

\begin{CodeChunk}

\begin{CodeInput}
R> round(steadyStates(mobilityMc), 2)
\end{CodeInput}

\begin{CodeOutput}
     Bottom  2nd  3rd  Top
[1,]   0.25 0.25 0.25 0.25
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{sec:gen}{%
\subsection{Genetics and Medicine}\label{sec:gen}}

This section contains two examples: the first shows the use of Markov chain models in genetics, the second shows an application of Markov chains in modelling diseases' dynamics.

\hypertarget{sec:genetics}{%
\subsubsection{Genetics}\label{sec:genetics}}

\cite{averyHenderson} discusses the use of Markov chains in model Preprogucacon gene protein bases sequence. The \texttt{preproglucacon} dataset in \pkg{markovchain} contains the dataset shown in the package.

\begin{CodeChunk}

\begin{CodeInput}
R> data("preproglucacon", package = "markovchain")
\end{CodeInput}
\end{CodeChunk}

It is possible to model the transition probabilities between bases as shown in the following code.

\begin{CodeChunk}

\begin{CodeInput}
R> mcProtein <- markovchainFit(preproglucacon$preproglucacon, 
R+                           name = "Preproglucacon MC")$estimate
R> mcProtein
\end{CodeInput}

\begin{CodeOutput}
Preproglucacon MC 
 A  4 - dimensional discrete Markov Chain defined by the following states: 
 A, C, G, T 
 The transition matrix  (by rows)  is defined as follows: 
          A         C          G         T
A 0.3585271 0.1434109 0.16666667 0.3313953
C 0.3840304 0.1558935 0.02281369 0.4372624
G 0.3053097 0.1991150 0.15044248 0.3451327
T 0.2844523 0.1819788 0.17667845 0.3568905
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{sec:medicine}{%
\subsubsection{Medicine}\label{sec:medicine}}

Discrete-time Markov chains are also employed to study the progression of chronic diseases. The following example is taken from \cite{craigSendi}. Starting from six month follow-up data, the maximum likelihood estimation of the monthly transition matrix is obtained. This transition matrix aims to describe the monthly progression of CD4-cell counts of HIV infected subjects.

\begin{CodeChunk}

\begin{CodeInput}
R> craigSendiMatr <- matrix(c(682, 33, 25,
R+               154, 64, 47,
R+               19, 19, 43), byrow = T, nrow = 3)
R> hivStates <- c("0-49", "50-74", "75-UP")
R> rownames(craigSendiMatr) <- hivStates
R> colnames(craigSendiMatr) <- hivStates
R> craigSendiTable <- as.table(craigSendiMatr)
R> mcM6 <- as(craigSendiTable, "markovchain")
R> mcM6@name <- "Zero-Six month CD4 cells transition"
R> mcM6
\end{CodeInput}

\begin{CodeOutput}
Zero-Six month CD4 cells transition 
 A  3 - dimensional discrete Markov Chain defined by the following states: 
 0-49, 50-74, 75-UP 
 The transition matrix  (by rows)  is defined as follows: 
           0-49      50-74      75-UP
0-49  0.9216216 0.04459459 0.03378378
50-74 0.5811321 0.24150943 0.17735849
75-UP 0.2345679 0.23456790 0.53086420
\end{CodeOutput}
\end{CodeChunk}

As shown in the paper, the second passage consists in the decomposition of \(M_{6}=V \cdot D \cdot V^{-1}\) in order to obtain \(M_{1}\) as \(M_{1}=V \cdot D^{1/6} \cdot V^{-1}\) .

\begin{CodeChunk}

\begin{CodeInput}
R> eig <- eigen(mcM6@transitionMatrix)
R> D <- diag(eig$values)
\end{CodeInput}
\end{CodeChunk}

\begin{CodeChunk}

\begin{CodeInput}
R> V <- eig$vectors 
R> V %*% D %*% solve(V)
\end{CodeInput}

\begin{CodeOutput}
          [,1]       [,2]       [,3]
[1,] 0.9216216 0.04459459 0.03378378
[2,] 0.5811321 0.24150943 0.17735849
[3,] 0.2345679 0.23456790 0.53086420
\end{CodeOutput}

\begin{CodeInput}
R> d <- D ^ (1/6)
R> M <- V %*% d %*% solve(V)
R> mcM1 <- new("markovchain", transitionMatrix = M, states = hivStates)
\end{CodeInput}
\end{CodeChunk}

\hypertarget{discussion-issues-and-future-plans}{%
\section{Discussion, issues and future plans}\label{discussion-issues-and-future-plans}}

The \pkg{markovchain} package has been designed in order to provide easily handling of DTMC and communication with alternative packages.

The package has known several improvements in the recent years: many functionalities added, porting the software in Rcpp \pkg{Rcpp} package \citep{RcppR} and many methodological improvements that have improved the software reliability.

\hypertarget{sec:aknowledgements}{%
\section{Aknowledgments}\label{sec:aknowledgements}}

The package was selected for Google Summer of Code 2015 support. The authors wish to thank Michael Cole, Tobi Gutman and Mildenberger Thoralf for their suggestions and bug checks. A final thanks also to Dr.~Simona C. Minotti and Dr.~Mirko Signorelli for their support in drafting this version of the vignettes.

\clearpage

\renewcommand\refname{References}
\bibliography{markovchainBiblio.bib}


\end{document}

